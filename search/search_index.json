{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome!\n\n\nTutorials\n\n\nThis site contains tutorials for using \nGalaxy Australia\n.\n\n\nTo use the tutorials:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nWeb address: \nwww.usegalaxy.org.au\n\n\n\n\nSupport\n\n\n\n\nRCCC\n\n\nQCIF\n\n\nMB\n\n\nBPA\n\n\nEMBL-ABR\n\n\nNCRIS\n\n\nRDS\n\n\nANDS\n\n\nNectar", 
            "title": "Welcome"
        }, 
        {
            "location": "/#welcome", 
            "text": "", 
            "title": "Welcome!"
        }, 
        {
            "location": "/#tutorials", 
            "text": "This site contains tutorials for using  Galaxy Australia .  To use the tutorials:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   Web address:  www.usegalaxy.org.au", 
            "title": "Tutorials"
        }, 
        {
            "location": "/#support", 
            "text": "RCCC  QCIF  MB  BPA  EMBL-ABR  NCRIS  RDS  ANDS  Nectar", 
            "title": "Support"
        }, 
        {
            "location": "/modules/galaxy/", 
            "text": "What is Galaxy Australia?\n\n\nWhat is Galaxy?\n\n\nGalaxy is a web-based analysis and workflow platform.\n\n\n\n\nDesigned for biologists\n\n\nEasily accessible via a web page\n\n\nFree to use\n\n\nYou can upload your own data\n\n\nYou can access shared data\n\n\nUse common bioinformatics tools\n\n\nDevelop workflows\n\n\n\n\nWhat does Galaxy look like?\n\n\n\n\nTools\n on the left\n\n\nViewing\n panel in the middle\n\n\nHistory\n of analysis and files on the right\n\n\n\n\n\n\nCan I use Galaxy?\n\n\nYes!\n\n\n\n\nGalaxy is free to use and available for everyone.\n\n\nAustralian researchers may find Galaxy Australia particularly suited to their analysis needs as it has been developed in consultation with scientists across the country.\n\n\n\n\nWhat is Galaxy Australia?\n\n\nGalaxy Australia has been developed for Australian researchers. It replaces the previous servers called Galaxy-Qld and Galaxy-Mel.\n\n\n\n\nWhere are the other Galaxy servers?\n\n\nA list of Galaxy servers is \nhere\n.\n\n\n\n\n\n\nWhat is on the other Galaxy servers?\n\n\nSome have a set of general tools, and some have been developed for particular analyses.\n\n\n\n\n\n\nCan I use more than one Galaxy server?\n\n\nYes, but you will need to register separately for each one, and they don\nt share data between them.\n\n\n\n\n\n\n\n\nLog in\n\n\n\n\nOpen your internet browser.\n\n\nUse Safari, Chrome or Firefox. Don\nt use Internet Explorer.\n\n\nType in the address of Galaxy Australia: \nusegalaxy.org.au\n\n\nThe first time you use Galaxy Australia, click on the \nLogin or Register\n tab and select \nRegister\n.\n\n\nEnter the details required and click \nSubmit\n.\n\n\nLog in, and refresh the page.\n\n\n\n\n\n\n\n\nEach time you use this Galaxy server, log in to see your data and histories.\n\n\nIf you are using a different Galaxy server, you would need to register/log in to that server.\n\n\n\n\nUse tools\n\n\n\n\n\n\nAvailable tools are in the left hand panel. Find the tool you want or use the search bar at the top of the tools.\n\n\n\n\n\n\nClick on the tool you want to use.\n\n\n\n\n\n\nThe tool interface will appear in the centre Galaxy panel. Check the settings.\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\n\n\nWhen the tool has finished, output file(s) will appear at the top of your \nCurrent History\n in the right hand panel.\n\n\n\n\n\n\nClick on the eye icon next to a file to view it.\n\n\n\n\n\n\nTo access older histories, use the button at the top right of the History panel.\n\n\n\n\n\n\nMore information\n\n\nMore information about the Galaxy project can be found \nhere\n.\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Get started"
        }, 
        {
            "location": "/modules/galaxy/#what-is-galaxy-australia", 
            "text": "", 
            "title": "What is Galaxy Australia?"
        }, 
        {
            "location": "/modules/galaxy/#what-is-galaxy", 
            "text": "Galaxy is a web-based analysis and workflow platform.   Designed for biologists  Easily accessible via a web page  Free to use  You can upload your own data  You can access shared data  Use common bioinformatics tools  Develop workflows", 
            "title": "What is Galaxy?"
        }, 
        {
            "location": "/modules/galaxy/#what-does-galaxy-look-like", 
            "text": "Tools  on the left  Viewing  panel in the middle  History  of analysis and files on the right", 
            "title": "What does Galaxy look like?"
        }, 
        {
            "location": "/modules/galaxy/#can-i-use-galaxy", 
            "text": "Yes!   Galaxy is free to use and available for everyone.  Australian researchers may find Galaxy Australia particularly suited to their analysis needs as it has been developed in consultation with scientists across the country.", 
            "title": "Can I use Galaxy?"
        }, 
        {
            "location": "/modules/galaxy/#what-is-galaxy-australia_1", 
            "text": "Galaxy Australia has been developed for Australian researchers. It replaces the previous servers called Galaxy-Qld and Galaxy-Mel.   Where are the other Galaxy servers?  A list of Galaxy servers is  here .    What is on the other Galaxy servers?  Some have a set of general tools, and some have been developed for particular analyses.    Can I use more than one Galaxy server?  Yes, but you will need to register separately for each one, and they don t share data between them.", 
            "title": "What is Galaxy Australia?"
        }, 
        {
            "location": "/modules/galaxy/#log-in", 
            "text": "Open your internet browser.  Use Safari, Chrome or Firefox. Don t use Internet Explorer.  Type in the address of Galaxy Australia:  usegalaxy.org.au  The first time you use Galaxy Australia, click on the  Login or Register  tab and select  Register .  Enter the details required and click  Submit .  Log in, and refresh the page.     Each time you use this Galaxy server, log in to see your data and histories.  If you are using a different Galaxy server, you would need to register/log in to that server.", 
            "title": "Log in"
        }, 
        {
            "location": "/modules/galaxy/#use-tools", 
            "text": "Available tools are in the left hand panel. Find the tool you want or use the search bar at the top of the tools.    Click on the tool you want to use.    The tool interface will appear in the centre Galaxy panel. Check the settings.    Click  Execute .    When the tool has finished, output file(s) will appear at the top of your  Current History  in the right hand panel.    Click on the eye icon next to a file to view it.    To access older histories, use the button at the top right of the History panel.", 
            "title": "Use tools"
        }, 
        {
            "location": "/modules/galaxy/#more-information", 
            "text": "More information about the Galaxy project can be found  here .", 
            "title": "More information"
        }, 
        {
            "location": "/modules/galaxy/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/intro/", 
            "text": "Learn key tasks\n\n\n\n\nThis is a short introduction to the Galaxy user interface - the web page that you interact with.\n\n\nWe will cover key tasks in Galaxy: uploading files, using tools, and viewing histories.\n\n\n\n\nNew to Galaxy?\n First try the \nintroduction\n\n\nWhat does Galaxy look like?\n\n\n\n\n\n\nBrowse to your Galaxy instance and log in or register.\n\n\n\n\nUse Chrome, Safari or Firefox as your browser, not Internet Explorer.\n\n\nThis is an image of Galaxy Australia, located at \nwww.usegalaxy.org.au\n.\n\n\n\n\n\n\n\n\nThe particular Galaxy server that you are using may look slightly different and have a different web address.\n\n\n\n\nFor example, the main Galaxy server is \nwww.usegalaxy.org\n.\n\n\n\n\n\n\n\n\n\n\n\n\nThe Galaxy page is divided into three panels:\n\n\nTools on the left\n\n\nViewing panel in the middle\n\n\nHistory of analysis and files on the right\n\n\n\n\n\n\n\n\n\n\n\n\nThe first time you use Galaxy, there will be no files in your history panel.\n\n\n\n\nName your current history\n\n\nYour \nHistory\n is in the panel at the right.\n\n\n\n\nGo to the History panel\n\n\nClick on the history name (\nUnnamed history\n)\n\n\nType in a new name, for example, \nMy-Analysis\n\n\nPress Enter\n\n\n\n\n\n\n\nUpload a file\n\n\nYour \nTools\n are in the panel at the left.\n\n\n\n\nGo to the Tools panel\n\n\nClick \nGet Data\n (at the top of the list)\n\n\nClick \nUpload File\n\n\n\n\nThis brings up a box:\n\n\n\n\n\n\n\n\n\nClick \nPaste/Fetch data\n\n\nPaste in the address of a file: \nhttps://zenodo.org/record/582600/files/mutant_R1.fastq\n\n\nThen click \nStart\n.\n\n\nThen click \nClose\n.\nYour uploaded file is now in your current history.\n\n\n\n\nWhen the file has uploaded to Galaxy, it will turn green.\n\n\n\n\nGrey means \nwaiting to run\n; yellow means \nin progress\n.\n\n\n\n\nWhat is this file?\n\n\n\n\nClick on the eye icon next to the file name, to look at the file contents.\n\n\n\n\n\n\nThe contents of the file will be displayed in the centre Galaxy panel.\n\n\n\n\nThis file contains DNA sequencing reads from a bacteria, in FASTQ format:\n\n\n\n\n\n\nClick here for more information about FASTQ format.\n\n\nUse a tool\n\n\nLet\ns look at the quality of the reads in this file.\n\n\n\n\nIn the tools panel search box, type in \nFastQC\n.\n\n\nClick on the tool \nFastQC\n\n\nThis brings up a window in the centre of the screen.\n\n\nFor \nShort read data from your current history\n select the FASTQ file that we uploaded.\n\n\nLeave the other parameters as they are.\n\n\nClick \nExecute\n.\n\n\nThis tool will run and the two output files will appear at the top of your history panel.\n\n\n\n\nHow do I choose the correct parameters for my analysis?\n\n\n\n\nUnder the tool interface panel in Galaxy there will usually be a description of the tool function and options, and a link to the tool\ns documentation.\n\n\nWhen trying a tool, you can usually use most of the default settings, as these are typically (generally) appropriate.\n\n\nWhen doing your own analyses, it is definitely recommended that you read about the tool parameters in more detail in the documentation, and adjust to your data and analysis accordingly.\n\n\n\n\nView results\n\n\nWe will look at the output file called \nFastQC on data 1: Webpage\n.\n\n\n\n\nNote that Galaxy has given this file a name according to both the tool (FastQC) and the data file (\ndata 1\n) that it used.\n\n\n\n\nThe name \ndata 1\n means the data file (our FASTQ file) which was file number 1 in Galaxy\ns current history.\n\n\n\n\n\n\nClick on the eye icon next to the output file.\n\n\n\n\nThe information is displayed in the centre panel.\n\n\n\n\n\n\nThis tool has summarised information about all of the reads in our FASTQ file.\n\n\n\n\nWhat was the length of the reads in the input FASTQ file?\n\n\nDo these reads have higher quality scores in the centre or at the ends?\n\n\n\n\nOptional: Run another tool\n\n\nLet\ns run a tool to filter out lower-quality reads from our FASTQ file.\n\n\n\n\nIn the tool panel search box, type in \nFilter by quality\n.\n\n\nClick on the tool \nFilter by quality\n\n\nUnder \nLibrary to filter\n, Galaxy will probably have found your input FASTQ file. If not, select this file in the drop-down box.\n\n\nUnder \nQuality cut-off value\n, type in 35.\n\n\nUnder \nPercent of bases in sequence that must have quality equal to / higher than cut-off value\n, type in 80.\n\n\nClick \nExecute\n.\n\n\n\n\nAfter the tool has run, the output file will appear at the top of your History panel.\n\n\n\n\nThis file will be called \nFilter by quality on data 1\n.\n\n\nRemember that Galaxy has named this file according to the tool it used (\nFilter by quality\n) and the data file (\ndata 1\n).\n\n\nThe actual numbers in front of the files in the history are not important.\n\n\n\n\nWhat are the results from this filtering tool?\n\n\n\n\nWe could click on the eye icon to view the contents of this output file, but it will not be very informative - we will just see a list of reads.\n\n\nInstead, let\ns click on the output file name in the History panel. This expands the information about the file.\n\n\nWe can see that 1786 low-quality reads were discarded.\n\n\n\n\n\n\nOptional: Re-run that tool with changed settings\n\n\nWe have now decided that our input reads have to be filtered to an even higher standard.\n\n\n\n\n\n\nWe will change the filter settings and re-run the tool.\n\n\n\n\n\n\nIn the History panel, find the output file from the first time we ran the filter tool.\n\n\n\n\nThis file is called \nFilter by quality on data 1\n.\n\n\nClick on the icon with two arrows - this means \nrun this tool again\n.\n\n\n\n\n\nThis brings up the tool interface in the centre panel.\n\n\nChange the settings to something even stricter. For example, you might decide you want 80 percent of bases to have a quality of 36 or higher, instead of 35.\n\n\nClick \nExecute\n.\n\n\n\n\nView the results:\n\n\n\n\nClick on the output file name to expand the information. (\nNote\n: not the eye icon.)\n\n\nHow many reads were discarded under these new filtering conditions?\n\n\n\n\nYou can re-run a tool many times with different settings.\n\n\n\n\nEach time you re-run the tool, the new output file will appear at the top of your current history.\n\n\n\n\nCreate a new history\n\n\nLet\ns create a new history.\n\n\n\n\nIn the History panel, click on the cog icon.\n\n\n\n\n\n\n\nSelect \nCreate New\n.\n\n\nName your history, \ne.g.\n \nNext-analysis\n\n\nPress Enter\n\n\n\n\nThis new history does not have any files in it yet.\n\n\nLook at all your histories\n\n\nWhere is your first history, called \nmy-analysis\n?\n\n\n\n\nIn the History panel, click on the \nView all histories\n icon.\n\n\n\n\n\n\n\nAll your histories are displayed here.\n\n\n\n\n\nDrag a file into your new history:\n\n\n\n\nClick on the FASTQ file in \nmy-analysis\n history\n\n\nDrag it into the \nNext-analysis\n history\n\n\nThis makes a copy of the file in the new history\n\n\nClick \nDone\n, or, if that button is not showing, click \nAnalyze Data\n in the menu panel across the top.\n\n\n\n\n\n\n\n\nYour main Galaxy window will now show the current history as \nNext-analysis\n, and it will have one file in it.\n\n\nYou can go back into the \nView all histories\n page and \nSwitch to\n a different history.\n\n\nSummary\n\n\nWhat have we learned?\n\n\n\n\nThe Galaxy interface has tools on the left, viewing pane in the middle, and a history of your data analysis on the right.\n\n\nYou can create a new history for each analysis. All your histories are saved.\n\n\nTo get data into Galaxy, you can upload a file by pasting in a web address. There are other ways to get data into Galaxy (not covered in this tutorial): you can upload a file from your computer, and you can import an entire history.\n\n\nChoose a tool and change any settings for your analysis.\n\n\nRun the tool. The output files will be saved at the top of your history.\n\n\nView the output files by clicking on the eye icon.\n\n\nView all your histories and move files between them. Switch to a different history.\n\n\nLog out of your Galaxy server. When you log back in (to the same server), your histories will all be there.\n\n\n\n\nConclusion\n\n\nWell done! You have completed the short introduction to Galaxy, where you named the history, uploaded a file, used a tool, and viewed results. Additional tutorials are available for a more in-depth introduction to Galaxy\ns features.\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-key-tasks-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Learn key tasks"
        }, 
        {
            "location": "/modules/intro/#learn-key-tasks", 
            "text": "This is a short introduction to the Galaxy user interface - the web page that you interact with.  We will cover key tasks in Galaxy: uploading files, using tools, and viewing histories.   New to Galaxy?  First try the  introduction", 
            "title": "Learn key tasks"
        }, 
        {
            "location": "/modules/intro/#what-does-galaxy-look-like", 
            "text": "Browse to your Galaxy instance and log in or register.   Use Chrome, Safari or Firefox as your browser, not Internet Explorer.  This is an image of Galaxy Australia, located at  www.usegalaxy.org.au .     The particular Galaxy server that you are using may look slightly different and have a different web address.   For example, the main Galaxy server is  www.usegalaxy.org .       The Galaxy page is divided into three panels:  Tools on the left  Viewing panel in the middle  History of analysis and files on the right       The first time you use Galaxy, there will be no files in your history panel.", 
            "title": "What does Galaxy look like?"
        }, 
        {
            "location": "/modules/intro/#name-your-current-history", 
            "text": "Your  History  is in the panel at the right.   Go to the History panel  Click on the history name ( Unnamed history )  Type in a new name, for example,  My-Analysis  Press Enter", 
            "title": "Name your current history"
        }, 
        {
            "location": "/modules/intro/#upload-a-file", 
            "text": "Your  Tools  are in the panel at the left.   Go to the Tools panel  Click  Get Data  (at the top of the list)  Click  Upload File   This brings up a box:     Click  Paste/Fetch data  Paste in the address of a file:  https://zenodo.org/record/582600/files/mutant_R1.fastq  Then click  Start .  Then click  Close .\nYour uploaded file is now in your current history.   When the file has uploaded to Galaxy, it will turn green.   Grey means  waiting to run ; yellow means  in progress .   What is this file?   Click on the eye icon next to the file name, to look at the file contents.    The contents of the file will be displayed in the centre Galaxy panel.   This file contains DNA sequencing reads from a bacteria, in FASTQ format:    Click here for more information about FASTQ format.", 
            "title": "Upload a file"
        }, 
        {
            "location": "/modules/intro/#use-a-tool", 
            "text": "Let s look at the quality of the reads in this file.   In the tools panel search box, type in  FastQC .  Click on the tool  FastQC  This brings up a window in the centre of the screen.  For  Short read data from your current history  select the FASTQ file that we uploaded.  Leave the other parameters as they are.  Click  Execute .  This tool will run and the two output files will appear at the top of your history panel.   How do I choose the correct parameters for my analysis?   Under the tool interface panel in Galaxy there will usually be a description of the tool function and options, and a link to the tool s documentation.  When trying a tool, you can usually use most of the default settings, as these are typically (generally) appropriate.  When doing your own analyses, it is definitely recommended that you read about the tool parameters in more detail in the documentation, and adjust to your data and analysis accordingly.", 
            "title": "Use a tool"
        }, 
        {
            "location": "/modules/intro/#view-results", 
            "text": "We will look at the output file called  FastQC on data 1: Webpage .   Note that Galaxy has given this file a name according to both the tool (FastQC) and the data file ( data 1 ) that it used.   The name  data 1  means the data file (our FASTQ file) which was file number 1 in Galaxy s current history.    Click on the eye icon next to the output file.   The information is displayed in the centre panel.    This tool has summarised information about all of the reads in our FASTQ file.   What was the length of the reads in the input FASTQ file?  Do these reads have higher quality scores in the centre or at the ends?", 
            "title": "View results"
        }, 
        {
            "location": "/modules/intro/#optional-run-another-tool", 
            "text": "Let s run a tool to filter out lower-quality reads from our FASTQ file.   In the tool panel search box, type in  Filter by quality .  Click on the tool  Filter by quality  Under  Library to filter , Galaxy will probably have found your input FASTQ file. If not, select this file in the drop-down box.  Under  Quality cut-off value , type in 35.  Under  Percent of bases in sequence that must have quality equal to / higher than cut-off value , type in 80.  Click  Execute .   After the tool has run, the output file will appear at the top of your History panel.   This file will be called  Filter by quality on data 1 .  Remember that Galaxy has named this file according to the tool it used ( Filter by quality ) and the data file ( data 1 ).  The actual numbers in front of the files in the history are not important.   What are the results from this filtering tool?   We could click on the eye icon to view the contents of this output file, but it will not be very informative - we will just see a list of reads.  Instead, let s click on the output file name in the History panel. This expands the information about the file.  We can see that 1786 low-quality reads were discarded.", 
            "title": "Optional: Run another tool"
        }, 
        {
            "location": "/modules/intro/#optional-re-run-that-tool-with-changed-settings", 
            "text": "We have now decided that our input reads have to be filtered to an even higher standard.    We will change the filter settings and re-run the tool.    In the History panel, find the output file from the first time we ran the filter tool.   This file is called  Filter by quality on data 1 .  Click on the icon with two arrows - this means  run this tool again .   This brings up the tool interface in the centre panel.  Change the settings to something even stricter. For example, you might decide you want 80 percent of bases to have a quality of 36 or higher, instead of 35.  Click  Execute .   View the results:   Click on the output file name to expand the information. ( Note : not the eye icon.)  How many reads were discarded under these new filtering conditions?   You can re-run a tool many times with different settings.   Each time you re-run the tool, the new output file will appear at the top of your current history.", 
            "title": "Optional: Re-run that tool with changed settings"
        }, 
        {
            "location": "/modules/intro/#create-a-new-history", 
            "text": "Let s create a new history.   In the History panel, click on the cog icon.    Select  Create New .  Name your history,  e.g.   Next-analysis  Press Enter   This new history does not have any files in it yet.", 
            "title": "Create a new history"
        }, 
        {
            "location": "/modules/intro/#look-at-all-your-histories", 
            "text": "Where is your first history, called  my-analysis ?   In the History panel, click on the  View all histories  icon.    All your histories are displayed here.   Drag a file into your new history:   Click on the FASTQ file in  my-analysis  history  Drag it into the  Next-analysis  history  This makes a copy of the file in the new history  Click  Done , or, if that button is not showing, click  Analyze Data  in the menu panel across the top.     Your main Galaxy window will now show the current history as  Next-analysis , and it will have one file in it.  You can go back into the  View all histories  page and  Switch to  a different history.", 
            "title": "Look at all your histories"
        }, 
        {
            "location": "/modules/intro/#summary", 
            "text": "What have we learned?   The Galaxy interface has tools on the left, viewing pane in the middle, and a history of your data analysis on the right.  You can create a new history for each analysis. All your histories are saved.  To get data into Galaxy, you can upload a file by pasting in a web address. There are other ways to get data into Galaxy (not covered in this tutorial): you can upload a file from your computer, and you can import an entire history.  Choose a tool and change any settings for your analysis.  Run the tool. The output files will be saved at the top of your history.  View the output files by clicking on the eye icon.  View all your histories and move files between them. Switch to a different history.  Log out of your Galaxy server. When you log back in (to the same server), your histories will all be there.", 
            "title": "Summary"
        }, 
        {
            "location": "/modules/intro/#conclusion", 
            "text": "Well done! You have completed the short introduction to Galaxy, where you named the history, uploaded a file, used a tool, and viewed results. Additional tutorials are available for a more in-depth introduction to Galaxy s features.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/modules/intro/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-key-tasks-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/intro/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/fastqc/", 
            "text": "FastQC in Galaxy\n\n\nAfter sequencing, the reads should be checked for their quality.\n\n\n\n\nThis tutorial demonstrates how to use the tool called FastQC to examine bacterial paired-end Illumina sequence reads.\n\n\nThe FastQC website is \nhere.\n\n\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nImport the data\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nCreate a new history for this analysis.\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\nFind the file called \nmutant_R1.fastq\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\n\n\nThe file name is quite long: let\ns change it:\n\n\n\n\nClick on the pencil icon next to the file name.\n\n\nIn the centre Galaxy panel, click in the box under \nName\n\n\nShorten the file name to \nmutant_R1.fastq\n\n\nThen click \nSave\n\n\n\n\n\n\nFASTQ is a file format for sequence reads that displays quality scores for each of the sequenced nucleotides.\n\n\n\n\nFor more information about FASTQ format see this \nlink\n.\n\n\nWe will evaluate the \nmutant_R1.fastq\n reads using the FastQC tool.\n\n\n\n\nRun FastQC\n\n\nIn the Tool panel search box, search for \nFastQC\n; then click on the tool \nFastQC\n.\n\n\nThe tool interface will appear in the centre Galaxy panel.\n\n\n\n\nfor \nShort read data from your current history\n: \nmutant_R1.fastq\n\n\nClick \nExecute\n\n\nIn the History pane, click on the \nrefresh\n icon to see if the analysis has finished.\n\n\n\n\nExamine output files\n\n\nOnce finished, examine the output called \nFastQC on data1:webpage\n (Hint: click the eye icon). It has a summary at the top of the page and a number of graphs.\n\n\nLook at:\n\n\n\n\n\n\nBasic Statistics\n\n\n\n\nSequence length\n: will be important in setting maximum k-mer size value for assembly.\n\n\nEncoding\n: The quality encoding type is important for quality trimming software.\n\n\n% GC\n: high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.\n\n\nTotal sequences\n: Total number of reads: gives you an idea of coverage.\n\n\n\n\n\n\n\n\nPer base sequence quality\n: Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run. In this case, all the reads are of relatively high quality across their length (150 bp).\n\n\n\n\n\n\n\n\n\n\nPer base N content\n: Presence of large numbers of Ns in reads may point to a poor quality sequencing run. You would need to trim these reads to remove Ns.\n\n\n\n\nGeneral questions you might ask about your input reads include:\n\n\n\n\nHow good is my read set?\n\n\nDo I need to ask for a new sequencing run?  \n\n\nIs it suitable for the analysis I need to do?\n\n\n\n\nFor a fuller discussion of FastQC outputs and warnings, see the \nFastQC website link\n, including the section on each of the output \nreports\n, and examples of \ngood\n and \nbad\n Illumina data.\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Quality control"
        }, 
        {
            "location": "/modules/fastqc/#fastqc-in-galaxy", 
            "text": "After sequencing, the reads should be checked for their quality.   This tutorial demonstrates how to use the tool called FastQC to examine bacterial paired-end Illumina sequence reads.  The FastQC website is  here.   New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "FastQC in Galaxy"
        }, 
        {
            "location": "/modules/fastqc/#import-the-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Create a new history for this analysis.  In a new browser tab, go to this webpage:     Find the file called  mutant_R1.fastq  Right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.   The file name is quite long: let s change it:   Click on the pencil icon next to the file name.  In the centre Galaxy panel, click in the box under  Name  Shorten the file name to  mutant_R1.fastq  Then click  Save    FASTQ is a file format for sequence reads that displays quality scores for each of the sequenced nucleotides.   For more information about FASTQ format see this  link .  We will evaluate the  mutant_R1.fastq  reads using the FastQC tool.", 
            "title": "Import the data"
        }, 
        {
            "location": "/modules/fastqc/#run-fastqc", 
            "text": "In the Tool panel search box, search for  FastQC ; then click on the tool  FastQC .  The tool interface will appear in the centre Galaxy panel.   for  Short read data from your current history :  mutant_R1.fastq  Click  Execute  In the History pane, click on the  refresh  icon to see if the analysis has finished.", 
            "title": "Run FastQC"
        }, 
        {
            "location": "/modules/fastqc/#examine-output-files", 
            "text": "Once finished, examine the output called  FastQC on data1:webpage  (Hint: click the eye icon). It has a summary at the top of the page and a number of graphs.  Look at:    Basic Statistics   Sequence length : will be important in setting maximum k-mer size value for assembly.  Encoding : The quality encoding type is important for quality trimming software.  % GC : high GC organisms don\u2019t tend to assemble well and may have an uneven read coverage distribution.  Total sequences : Total number of reads: gives you an idea of coverage.     Per base sequence quality : Dips in quality near the beginning, middle or end of the reads: determines possible trimming/cleanup methods and parameters and may indicate technical problems with the sequencing process/machine run. In this case, all the reads are of relatively high quality across their length (150 bp).      Per base N content : Presence of large numbers of Ns in reads may point to a poor quality sequencing run. You would need to trim these reads to remove Ns.   General questions you might ask about your input reads include:   How good is my read set?  Do I need to ask for a new sequencing run?    Is it suitable for the analysis I need to do?   For a fuller discussion of FastQC outputs and warnings, see the  FastQC website link , including the section on each of the output  reports , and examples of  good  and  bad  Illumina data.", 
            "title": "Examine output files"
        }, 
        {
            "location": "/modules/fastqc/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/spades/", 
            "text": "Assembly using Spades\n\n\nSpades is one of a number of \nde novo\n assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs.\n\n\n\n\nFor information about Spades see this \nlink\n.\n\n\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nThe data\n\n\nThe read set for today is from an imaginary \nStaphylococcus aureus\n bacterium with a miniature genome.\n\n\n\n\nThe whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.\n\n\nThe files we need for assembly are the \nmutant_R1.fastq\n and \nmutant_R2.fastq\n.\n\n\nThe reads are paired-end.\n\n\nEach read is 150 bases long. \n\n\nThe number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).\n\n\n\n\nImport the data\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nCreate a new history for this analysis.\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\nFind the file called \nmutant_R1.fastq\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\n\n\nThe file name is quite long: let\ns change it:\n\n\n\n\nClick on the pencil icon next to the file name.\n\n\nIn the centre Galaxy panel, click in the box under \nName\n\n\nShorten the file name to \nmutant_R1.fastq\n\n\nThen click \nSave\n\n\n\n\n\n\nRepeat these steps for the other set of reads (reverse reads) called \nmutant_R2.fq\n:\n\n\n\n\nIn a new browser tab, go to this webpage: \nhttp://doi.org/10.5281/zenodo.582600\n\n\nFind the file called \nmutant_R2.fastq\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\n\n\n\n\n\nWe now have two FASTQ read files in our history.\n\n\n\n\nClick on the eye icon next to one of the FASTQ sequence files.\n\n\nView the file in the centre Galaxy panel.\n\n\n\n\n\n\n\nAssemble the reads\n\n\nWe will perform a \nde novo\n assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)\n\n\n\n\nGo to the Tool panel and search for \nspades\n in the search box.\n\n\n\n\nClick on \nSPAdes\n\n\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nRun only Assembly\n: \nYes\n [the \nYes\n button should be darker grey]\n\n\nKmers to use separated by commas:\n \n33,55,91\n  [note: no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\nFiles \n Forward reads:\n \nmutant_R1.fastq\n  \n\n\nFiles \n Reverse reads:\n \nmutant_R2.fastq\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nExamine the output\n\n\n\n\nGalaxy is now running Spades on the reads for you.\n\n\n\n\nWhen it is finished, you will have five (or more) new files in your history, including:\n\n\n\n\ntwo FASTA files of the resulting contigs and scaffolds\n\n\ntwo files for statistics about these\n\n\nthe Spades logfile\n\n\n\n\n\n\n\n\n\n\n\n\nTo view the output, click on the eye icon next to each of the files.\n\n\nNote that the short reads have been assembled into much longer contigs.\n\n\n(However, in this case, the contigs have not been assembled into larger scaffolds.)\n\n\nThe stats files will give you the length of each of the contigs, and the file should look something like this:\n\n\n\n\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-assembly-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Genome assembly"
        }, 
        {
            "location": "/modules/spades/#assembly-using-spades", 
            "text": "Spades is one of a number of  de novo  assemblers that use short read sets as input (e.g. Illumina Reads), and the assembly method is based on de Bruijn graphs.   For information about Spades see this  link .   New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Assembly using Spades"
        }, 
        {
            "location": "/modules/spades/#the-data", 
            "text": "The read set for today is from an imaginary  Staphylococcus aureus  bacterium with a miniature genome.   The whole genome shotgun method used to sequence our mutant strain read set was produced on an Illumina DNA sequencing instrument.  The files we need for assembly are the  mutant_R1.fastq  and  mutant_R2.fastq .  The reads are paired-end.  Each read is 150 bases long.   The number of bases sequenced is equivalent to 19x the genome sequence of the wildtype strain. (Read coverage 19x - rather low!).", 
            "title": "The data"
        }, 
        {
            "location": "/modules/spades/#import-the-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Create a new history for this analysis.  In a new browser tab, go to this webpage:     Find the file called  mutant_R1.fastq  Right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.   The file name is quite long: let s change it:   Click on the pencil icon next to the file name.  In the centre Galaxy panel, click in the box under  Name  Shorten the file name to  mutant_R1.fastq  Then click  Save    Repeat these steps for the other set of reads (reverse reads) called  mutant_R2.fq :   In a new browser tab, go to this webpage:  http://doi.org/10.5281/zenodo.582600  Find the file called  mutant_R2.fastq  Right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.    We now have two FASTQ read files in our history.   Click on the eye icon next to one of the FASTQ sequence files.  View the file in the centre Galaxy panel.", 
            "title": "Import the data"
        }, 
        {
            "location": "/modules/spades/#assemble-the-reads", 
            "text": "We will perform a  de novo  assembly of the mutant FASTQ reads into long contiguous sequences (in FASTA format.)   Go to the Tool panel and search for  spades  in the search box.   Click on  SPAdes    Set the following parameters (leave other settings as they are):   Run only Assembly :  Yes  [the  Yes  button should be darker grey]  Kmers to use separated by commas:   33,55,91   [note: no spaces]    Coverage cutoff:   auto     Files   Forward reads:   mutant_R1.fastq     Files   Reverse reads:   mutant_R2.fastq        Your tool interface should look like this:      Click  Execute", 
            "title": "Assemble the reads"
        }, 
        {
            "location": "/modules/spades/#examine-the-output", 
            "text": "Galaxy is now running Spades on the reads for you.   When it is finished, you will have five (or more) new files in your history, including:   two FASTA files of the resulting contigs and scaffolds  two files for statistics about these  the Spades logfile       To view the output, click on the eye icon next to each of the files.  Note that the short reads have been assembled into much longer contigs.  (However, in this case, the contigs have not been assembled into larger scaffolds.)  The stats files will give you the length of each of the contigs, and the file should look something like this:", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/spades/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-assembly-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/spades/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/prokka/", 
            "text": "Genome annotation using Prokka\n\n\nBackground\n\n\nIn this section we will use a software tool called Prokka to annotate a draft genome sequence.\n\n\n\n\nProkka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.\n\n\nProkka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence.\n\n\nNote, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using \nProdigal\n; second, the \nfunction\n of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases.\n\n\nProkka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats.\n\n\nMore information about Prokka can be found \nhere\n.\n\n\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nInput data\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nCreate a new history for this analysis.\n\n\n\n\nProkka requires assembled contigs.\n\n\n\n\n\n\nIf you are continuing on from the previous workshop (\nAssembly with Spades\n), this file will be in your current history named something like \nSPAdes contigs(fasta)\n.\n\n\n\n\n\n\nOr, to upload a file of contigs:\n\n\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\nFind the file called \ncontigs.fasta\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel. When uploaded, the file name will turn green.\n\n\n\n\n\n\n\nRun Prokka\n\n\n\n\nGo to the Tool panel and search for \nprokka\n in the search box.\n\n\n\n\nClick on \nProkka\n\n\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nContigs to annotate\n: your \ncontigs.fasta\n file  \n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nGenus Name\n: \nStaphylococcus\n  \n\n\nSpecies Name\n: \naureus\n  \n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n  \n\n\n\n\nExamine the output\n\n\n\n\n\nOnce Prokka has finished, examine each of its output files.\n\n\n\n\nThe \nGFF\n and \nGBK\n files contain all of the information about the features annotated (in different formats.)\n\n\nThe \n.txt\n file contains a summary of the number of features annotated.\n\n\nThe \n.faa\n file contains the protein sequences of the genes annotated.\n\n\nThe \n.ffn\n file contains the nucleotide sequences of the genes annotated.\n\n\n\n\nView annotated features in JBrowse\n\n\nNow that we have annotated the draft genome sequence, we would like to view the sequence in the JBrowse genome viewer.\n\n\n\n\nGo to the Galaxy tool panel, and use the top search box to search for \nJBrowse\n.\n\n\n\n\nClick \nJBrowse\n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nUnder \nSelect the reference genome\n choose \nProkka on data XX:fna\n. This .fna sequence is the fasta nucleotide sequence, and will be the reference against which annotations are displayed.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nClick \nInsert Track Group\n\n\n\n\n\n\nUnder \nTrack Category\n type in \ngene annotations\n.\n\n\n\n\n\n\nClick \nInsert Annotation Track\n\n\n\n\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\n\n\n\n\nFor \nGFF/GFF3/BED Track Data\n select \nProkka on data XX:gff\n  [Note: not wildtype.gff]\n\n\n\n\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\n\n\n\n\nClick on \nJBrowse Styling Options \n\n\n\n\n\n\nUnder \nJBrowse style.label\n check that it says \nproduct,name,id\n.\n\n\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\nA new file will be created, called \nJBrowse on data XX and data XX - Complete\n. In place of \nXX\n, there will be numbers that will refer to the files that Galaxy used in your particular history. (This may take some time. If you would like to see a completed history for this tutorial, instructions are in the next section.)\n\n\n\n\n\n\nClick on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.\n\n\n\n\n\n\nUnder \nAvailable Tracks\n on the left, tick the box for \nProkka on data XX:gff\n.\n\n\n\n\n\n\nSelect contig 6 in the drop down box. You can only see one contig displayed at a time.\n\n\n\n\n\n\n\n\n\n\n\n\nUse the plus and minus buttons to zoom in and out, and the arrows to move left or right (or click and drag within the window to move left or right).\n\n\n\n\n\n\nZoom in to see the reference sequence at the top. JBrowse displays the sequence and a 6-frame amino acid translation.\n\n\n\n\n\n\nZoomed in view:\n\n\n\n\n\n\nRight click on a gene/feature annotation (the bars on the annotation track), then select \nView Details\n to see more information.\n\n\ngene name\n\n\nproduct name\n\n\nyou can download the FASTA sequence by clicking on the disk icon.\n\n\n\n\n\n\n\n\n\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-annotation-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Genome annotation"
        }, 
        {
            "location": "/modules/prokka/#genome-annotation-using-prokka", 
            "text": "", 
            "title": "Genome annotation using Prokka"
        }, 
        {
            "location": "/modules/prokka/#background", 
            "text": "In this section we will use a software tool called Prokka to annotate a draft genome sequence.   Prokka is a \u201cwrapper\u201d; it collects together several pieces of software (from various authors), and so avoids \u201cre-inventing the wheel\u201d.  Prokka finds and annotates features (both protein coding regions and RNA genes, i.e. tRNA, rRNA) present on on a sequence.  Note, Prokka uses a two-step process for the annotation of protein coding regions: first, protein coding regions on the genome are identified using  Prodigal ; second, the  function  of the encoded protein is predicted by similarity to proteins in one of many protein or protein domain databases.  Prokka is a software tool that can be used to annotate bacterial, archaeal and viral genomes quickly, generating standard output files in GenBank, EMBL and gff formats.  More information about Prokka can be found  here .   New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Background"
        }, 
        {
            "location": "/modules/prokka/#input-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Create a new history for this analysis.   Prokka requires assembled contigs.    If you are continuing on from the previous workshop ( Assembly with Spades ), this file will be in your current history named something like  SPAdes contigs(fasta) .    Or, to upload a file of contigs:   In a new browser tab, go to this webpage:     Find the file called  contigs.fasta  Right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel. When uploaded, the file name will turn green.", 
            "title": "Input data"
        }, 
        {
            "location": "/modules/prokka/#run-prokka", 
            "text": "Go to the Tool panel and search for  prokka  in the search box.   Click on  Prokka    Set the following parameters (leave other settings as they are):   Contigs to annotate : your  contigs.fasta  file    Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Genus Name :  Staphylococcus     Species Name :  aureus     Use genus-specific BLAST database   No        Your tool interface should look like this:    Click  Execute", 
            "title": "Run Prokka"
        }, 
        {
            "location": "/modules/prokka/#examine-the-output", 
            "text": "Once Prokka has finished, examine each of its output files.   The  GFF  and  GBK  files contain all of the information about the features annotated (in different formats.)  The  .txt  file contains a summary of the number of features annotated.  The  .faa  file contains the protein sequences of the genes annotated.  The  .ffn  file contains the nucleotide sequences of the genes annotated.", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/prokka/#view-annotated-features-in-jbrowse", 
            "text": "Now that we have annotated the draft genome sequence, we would like to view the sequence in the JBrowse genome viewer.   Go to the Galaxy tool panel, and use the top search box to search for  JBrowse .   Click  JBrowse    Under  Reference genome to display  choose  Use a genome from history .    Under  Select the reference genome  choose  Prokka on data XX:fna . This .fna sequence is the fasta nucleotide sequence, and will be the reference against which annotations are displayed.    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Click  Insert Track Group    Under  Track Category  type in  gene annotations .    Click  Insert Annotation Track    For  Track Type  choose  GFF/GFF3/BED/GBK Features    For  GFF/GFF3/BED Track Data  select  Prokka on data XX:gff   [Note: not wildtype.gff]    Under  JBrowse Track Type[Advanced]  select  Canvas Features .    Click on  JBrowse Styling Options     Under  JBrowse style.label  check that it says  product,name,id .    Under  Track Visibility  choose  On for new users .    Your tool interface should look like this:     Click  Execute   A new file will be created, called  JBrowse on data XX and data XX - Complete . In place of  XX , there will be numbers that will refer to the files that Galaxy used in your particular history. (This may take some time. If you would like to see a completed history for this tutorial, instructions are in the next section.)    Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.    Under  Available Tracks  on the left, tick the box for  Prokka on data XX:gff .    Select contig 6 in the drop down box. You can only see one contig displayed at a time.       Use the plus and minus buttons to zoom in and out, and the arrows to move left or right (or click and drag within the window to move left or right).    Zoom in to see the reference sequence at the top. JBrowse displays the sequence and a 6-frame amino acid translation.    Zoomed in view:    Right click on a gene/feature annotation (the bars on the annotation track), then select  View Details  to see more information.  gene name  product name  you can download the FASTA sequence by clicking on the disk icon.", 
            "title": "View annotated features in JBrowse"
        }, 
        {
            "location": "/modules/prokka/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-annotation-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/prokka/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/snippy/", 
            "text": "Variant calling with Snippy\n\n\nVariant calling is the process of identifying differences between two genome samples.\n\n\n\n\nDifferences are usually limited to single nucleotide polymorphisms (SNPs) and small insertions and deletions (indels).\n\n\nLarger structural variation such as inversions, duplications and large deletions are not typically covered by \nvariant calling\n.\n\n\nIn this tutorial, we will use the tool \nSnippy\n (link to Snippy is \nhere\n).\n\n\nSnippy uses a tool to align the reads to a reference genome, and another tool to decide (\ncall\n) if the discrepancies are real variants.\n\n\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\n\n\n\nGet data\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nCreate a new history for this analysis.\n\n\n\n\nGet data:\n\n\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\nFind the file called \nmutant_R1.fastq\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\nShorten the file name if you wish. (Click the pencil icon).\n\n\n\n\nRepeat these steps for the other set of reads (reverse reads) called \nmutant_R2.fq\n:\n\n\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\nFind the file called \nmutant_R2.fastq\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\nShorten the file name if you wish.\n\n\n\n\nRepeat these steps for three other files: \nwildtype.gbk\n, \nwildtype.gff\n and \nwildtype.fna\n.\n\n\nCall variants with Snippy\n\n\nGo to the Tool panel and search for \nsnippy\n in the search box.\n\n\n\n\nClick on \nsnippy\n\n\n\n\nSet the following parameters (leave other settings as they are):\n\n\n\n\nFor \nReference type\n select \nGenbank\n.\n\n\nThen for \nReference Genbank\n choose the \nwildtype.gbk\n file.\n\n\nFor \nSingle or Paired-end reads\n choose \nPaired\n.\n\n\nThen choose the first set of reads, \nmutant_R1.fastq\n and second set of reads, \nmutant_R2.fastq\n.\n\n\nFor \nCleanup the non-snp output files\n select \nNo\n. The box will be a darker grey.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nExamine Snippy output\n\n\n\n\n\nFrom Snippy, there are 10 output files in various formats.\n\n\n\n\nGo to the \ntable\n file called \nsnippy on data XX, data XX and data XX table\n and click on the eye icon.\n\n\n(The XX refers to the number that Galaxy has given your files.)\n\n\nWe can see a list of variants. Look in column 3 to see which types the variants are, such as a SNP or a deletion.\n\n\nLook at the third variant called. This is a T\nA mutation, causing a stop codon. Look at column 14: the product of this gene is a methicillin resistance protein. Methicillin is an antibiotic. What might be the result of such a mutation? \n\n\n\n\nView Snippy output in JBrowse\n\n\n\n\n\n\nGo to the Galaxy tools panel, and use the search box at the top to search for \nJBrowse\n.\n\n\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\n\n\nUnder \nSelect the reference genome\n choose \nwildtype.fna\n. This sequence will be the reference against which annotations are displayed.\n\n\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nWe will now set up three different tracks - these are datasets displayed underneath the reference sequence (which is displayed as nucleotides in FASTA format). We will choose to display the sequence reads (the .bam file), the variants found by snippy (the .gff file) and the annotated reference genome (the wildtype.gff)\n\n\n\n\n\n\nTrack 1 - sequence reads\n\n\n\n\nClick \nInsert Track Group\n\n\nFor \nTrack Cateogry\n name it \nsequence reads\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nBAM Pileups\n\n\nFor \nBAM Track Data\n select \nthe snippy bam file\n\n\nFor \nAutogenerate SNP Track\n select \nYes\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\nTrack 2 - variants\n\n\n\n\nClick \nInsert Track Group\n again\n\n\nFor \nTrack Category\n name it \nvariants\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\nFor \nTrack Data\n select \nthe snippy snps gff file\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\nTrack 3 - annotated reference\n\n\n\n\nClick \nInsert Track Group\n again\n\n\nFor \n Track Category\n name it \nannotated reference\n\n\nClick \nInsert Annotation Track\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\nFor \nTrack Data\n select \nwildtype.gff\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\nClick on \nJBrowse Styling Options \n\n\nUnder \nJBrowse style.label\n add in the word \nproduct\n.\n\n\nUnder \nJBrowse style.description\n check that it says \nproduct,name,id\n.\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nA new file will be created, called \nJBrowse on data XX and data XX - Complete\n. (This may take some time. If you would like to see a completed history for this tutorial, instructions are in the next section.)\n\n\n\n\n\n\nClick on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.\n\n\n\n\n\n\nOn the left, tick boxes to display the tracks\n\n\n\n\n\n\nUse the minus button to zoom out to see:\n\n\n\n\nsequence reads and their coverage (the grey graph)\n\n\n\n\n\n\n\n\nUse the plus button to zoom in to see:\n\n\n\n\nprobable real variants (a whole column of snps)\n\n\nprobable errors (single one here and there)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the coordinates box, type in \n47299\n and then \nGo\n to see the position of the SNP discussed above.\n\n\nthe correct codon at this position is TGT, coding for the amino acid Cysteine, in the middle row of the amino acid translations.\n\n\nthe mutation of T \n A turns this triplet into TGA, a stop codon.\n\n\n\n\n\n\n\n\n    \n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-variant-calling-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Variant calling - bacteria"
        }, 
        {
            "location": "/modules/snippy/#variant-calling-with-snippy", 
            "text": "Variant calling is the process of identifying differences between two genome samples.   Differences are usually limited to single nucleotide polymorphisms (SNPs) and small insertions and deletions (indels).  Larger structural variation such as inversions, duplications and large deletions are not typically covered by  variant calling .  In this tutorial, we will use the tool  Snippy  (link to Snippy is  here ).  Snippy uses a tool to align the reads to a reference genome, and another tool to decide ( call ) if the discrepancies are real variants.   New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Variant calling with Snippy"
        }, 
        {
            "location": "/modules/snippy/#get-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Create a new history for this analysis.   Get data:   In a new browser tab, go to this webpage:     Find the file called  mutant_R1.fastq  Right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.  Shorten the file name if you wish. (Click the pencil icon).   Repeat these steps for the other set of reads (reverse reads) called  mutant_R2.fq :   In a new browser tab, go to this webpage:     Find the file called  mutant_R2.fastq  Right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.  Shorten the file name if you wish.   Repeat these steps for three other files:  wildtype.gbk ,  wildtype.gff  and  wildtype.fna .", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/snippy/#call-variants-with-snippy", 
            "text": "Go to the Tool panel and search for  snippy  in the search box.   Click on  snippy   Set the following parameters (leave other settings as they are):   For  Reference type  select  Genbank .  Then for  Reference Genbank  choose the  wildtype.gbk  file.  For  Single or Paired-end reads  choose  Paired .  Then choose the first set of reads,  mutant_R1.fastq  and second set of reads,  mutant_R2.fastq .  For  Cleanup the non-snp output files  select  No . The box will be a darker grey.   Your tool interface should look like this:    Click  Execute .", 
            "title": "Call variants with Snippy"
        }, 
        {
            "location": "/modules/snippy/#examine-snippy-output", 
            "text": "From Snippy, there are 10 output files in various formats.   Go to the  table  file called  snippy on data XX, data XX and data XX table  and click on the eye icon.  (The XX refers to the number that Galaxy has given your files.)  We can see a list of variants. Look in column 3 to see which types the variants are, such as a SNP or a deletion.  Look at the third variant called. This is a T A mutation, causing a stop codon. Look at column 14: the product of this gene is a methicillin resistance protein. Methicillin is an antibiotic. What might be the result of such a mutation?", 
            "title": "Examine Snippy output"
        }, 
        {
            "location": "/modules/snippy/#view-snippy-output-in-jbrowse", 
            "text": "Go to the Galaxy tools panel, and use the search box at the top to search for  JBrowse .    Under  Reference genome to display  choose  Use a genome from history .    Under  Select the reference genome  choose  wildtype.fna . This sequence will be the reference against which annotations are displayed.    For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    We will now set up three different tracks - these are datasets displayed underneath the reference sequence (which is displayed as nucleotides in FASTA format). We will choose to display the sequence reads (the .bam file), the variants found by snippy (the .gff file) and the annotated reference genome (the wildtype.gff)    Track 1 - sequence reads   Click  Insert Track Group  For  Track Cateogry  name it  sequence reads  Click  Insert Annotation Track  For  Track Type  choose  BAM Pileups  For  BAM Track Data  select  the snippy bam file  For  Autogenerate SNP Track  select  Yes  Under  Track Visibility  choose  On for new users .   Track 2 - variants   Click  Insert Track Group  again  For  Track Category  name it  variants  Click  Insert Annotation Track  For  Track Type  choose  GFF/GFF3/BED/GBK Features  For  Track Data  select  the snippy snps gff file  Under  Track Visibility  choose  On for new users .   Track 3 - annotated reference   Click  Insert Track Group  again  For   Track Category  name it  annotated reference  Click  Insert Annotation Track  For  Track Type  choose  GFF/GFF3/BED/GBK Features  For  Track Data  select  wildtype.gff  Under  JBrowse Track Type[Advanced]  select  Canvas Features .  Click on  JBrowse Styling Options   Under  JBrowse style.label  add in the word  product .  Under  JBrowse style.description  check that it says  product,name,id .   Under  Track Visibility  choose  On for new users .    Click  Execute    A new file will be created, called  JBrowse on data XX and data XX - Complete . (This may take some time. If you would like to see a completed history for this tutorial, instructions are in the next section.)    Click on the eye icon next to the file name. The JBrowse window will appear in the centre Galaxy panel.    On the left, tick boxes to display the tracks    Use the minus button to zoom out to see:   sequence reads and their coverage (the grey graph)     Use the plus button to zoom in to see:   probable real variants (a whole column of snps)  probable errors (single one here and there)       In the coordinates box, type in  47299  and then  Go  to see the position of the SNP discussed above.  the correct codon at this position is TGT, coding for the amino acid Cysteine, in the middle row of the amino acid translations.  the mutation of T   A turns this triplet into TGA, a stop codon.", 
            "title": "View Snippy output in JBrowse"
        }, 
        {
            "location": "/modules/snippy/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-variant-calling-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/snippy/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/variants/", 
            "text": "Variant calling: Humans\n\n\nIntroduction\n\n\nNow updated for Galaxy Australia\n\n\nhttps://www.melbournebioinformatics.org.au/tutorials/tutorials/variant_calling_galaxy_1/variant_calling_galaxy_1/\n\n\n\n\n\n\nAdvanced\n\n\nNot yet updated for Galaxy Australia\n\n\nhttps://www.melbournebioinformatics.org.au/tutorials/tutorials/var_detect_advanced/var_detect_advanced/", 
            "title": "Variant calling - human"
        }, 
        {
            "location": "/modules/variants/#variant-calling-humans", 
            "text": "", 
            "title": "Variant calling: Humans"
        }, 
        {
            "location": "/modules/variants/#introduction", 
            "text": "Now updated for Galaxy Australia  https://www.melbournebioinformatics.org.au/tutorials/tutorials/variant_calling_galaxy_1/variant_calling_galaxy_1/", 
            "title": "Introduction"
        }, 
        {
            "location": "/modules/variants/#advanced", 
            "text": "Not yet updated for Galaxy Australia  https://www.melbournebioinformatics.org.au/tutorials/tutorials/var_detect_advanced/var_detect_advanced/", 
            "title": "Advanced"
        }, 
        {
            "location": "/modules/abricate/", 
            "text": "Finding antibiotic-resistant genes\n\n\nIn this tutorial we will find antibiotic-resistant genes in a bacterial genome.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nGet data\n\n\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\n\n\n\n\nCreate a new history for this analysis.\n\n\n\n\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\n\n\nFind the file called \ncontigs.fasta\n\n\nRight click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data -\n Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel. When it has finished uploading, the file name will be green.\n\n\n\n\n\n\n\nFind antibiotic-resistant genes\n\n\nWe will use the tool called \nABRicate\n to find antibiotic-resistant genes in the (draft) genome.\n\n\n\n\nABRicate uses a \ndatabase\n of these genes called \nResFinder\n.\n\n\n\n\nIn the tools panel seach box, type in \nabricate\n\n\n\n\nClick on \nABRicate\n\n\nFor \nInput file\n choose \ncontigs.fasta\n (or the name of your own assembly file.)\n\n\nClick \nExecute\n.\n\n\n\n\nThere is one output file.\n\n\n\n\nClick on the eye icon to view.\n\n\nIt should look like this, although likely with a different number of rows.\n\n\n\n\n(We have used a miniature genome in this example, so only have a few rows).\n\n\n\n\n\n\nThis shows a table with one line for each antibiotic-resistant gene found, in which contig, at which position, and the % coverage.\n\n\n\n\n\n\n\n\nIn the output from Abricate, column 5 has the list of the antibiotic-resistant gene names.\n\n\n\n\n\n\nSome of these may be complete, exact matches, and some may have a gap/mutation in their sequence which can affect whether that protein is actually expressed.\n\n\n\n\n\n\nTo find out more about what type of AMR genes these are, you can search \nGenbank\n with the gene name (e.g. aadD).\n\n\n\n\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-Abricate-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#finding-antibiotic-resistant-genes", 
            "text": "In this tutorial we will find antibiotic-resistant genes in a bacterial genome.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Finding antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#get-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).    Create a new history for this analysis.    In a new browser tab, go to this webpage:      Find the file called  contigs.fasta  Right click on file name: select  copy link address  In Galaxy, go to  Get Data -  Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel. When it has finished uploading, the file name will be green.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/abricate/#find-antibiotic-resistant-genes", 
            "text": "We will use the tool called  ABRicate  to find antibiotic-resistant genes in the (draft) genome.   ABRicate uses a  database  of these genes called  ResFinder .   In the tools panel seach box, type in  abricate   Click on  ABRicate  For  Input file  choose  contigs.fasta  (or the name of your own assembly file.)  Click  Execute .   There is one output file.   Click on the eye icon to view.  It should look like this, although likely with a different number of rows.   (We have used a miniature genome in this example, so only have a few rows).    This shows a table with one line for each antibiotic-resistant gene found, in which contig, at which position, and the % coverage.     In the output from Abricate, column 5 has the list of the antibiotic-resistant gene names.    Some of these may be complete, exact matches, and some may have a gap/mutation in their sequence which can affect whether that protein is actually expressed.    To find out more about what type of AMR genes these are, you can search  Genbank  with the gene name (e.g. aadD).", 
            "title": "Find antibiotic-resistant genes"
        }, 
        {
            "location": "/modules/abricate/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-Abricate-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/abricate/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/mlst/", 
            "text": "Using MLST for bacterial typing\n\n\nA bacterial \ntype\n is a particular species with certain features.\n\n\n\n\nFor example, the bacterial type may be \nStaphyloccus aureus\n with resistance to penicillin.\n\n\nTo \ntype\n a bacteria, we can focus on several genes, and see which allele is present for each of these genes.\n\n\nEach bacterial species will have its own scheme, which is the set of genes that are looked at.\n\n\nOverall, this process is called multi-locus (= several genes) sequence typing, or MLST.\n\n\n\n\nIn this tutorial, we will perform MLST on a bacterial sequence.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nGet data\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\n\n\nIf you are using Galaxy Australia, look for the file we need in the \nShared Data\n.\n\n\n\n\nIn the top centre panel, go to \nShared Data\n\n\nClick \nHistories\n\n\nClick on the history named \nMLST-tutorial\n\n\nClick \nImport\n (in the top right corner)\n\n\nThis should now be your current history.\n\n\n\n\nAlternatively\n, we can get the sequence from Genbank.\n\n\n\n\nIn a new browser tab, go to this address: \nhttps://www.ncbi.nlm.nih.gov/nuccore/NC_002952.2\n\n\nClick \nSend to\n\n\nChoose \nFile\n\n\nChoose \nFASTA\n\n\nClick \nCreate File\n\n\n\n\nThis downloads \nsequence.fasta\n to your computer.\n\n\n\n\nIn the tool panel, go to \nGet Data -\n Upload File\n\n\n\n\nChoose local file\n: select \nsequence.fasta\n\n\nStart\n\n\nClose\n\n\n\n\nThis file should now be in your History panel. When it has completed uploading, the file name will be green.\n\n\nRun MLST\n\n\nIn the tool panel search box, search for MLST.\n\n\n\n\nClick \nMLST\n\n\n\n\nThe tool interface will appear in the centre Galaxy panel.\n\n\n\n\nFor \ninput_file\n, choose the sequence file that you uploaded, e.g. \nsequence.fasta\n\n\nClick \nExecute\n\n\n\n\nWhat does MLST do?\n\n\n\n\nTakes a fasta or genbank file\n\n\nScans this against all the typing schemes\n\n\nFinds the best match (e.g. a scheme for the correct species)\n\n\nReports the output:\n\n\nthe scheme chosen\n\n\nthe sequence type (e.g. ST = 21)\n\n\nthe genes in this scheme and the alleles found in the data\n\n\n\n\n\n\n\n\nView results\n\n\nThe results file will be at the top of your history panel.\n\n\n\n\n\n\nClick on the eye icon to view the output.\n\n\n\n\n\n\nYour results will be a single line.\n\n\n\n\n\n\n\n\nFor example:\n\n\n\n\nColumn 2: the scheme\n\n\nColumn 3: the sequence type\n\n\nThe rest of the columns: the gene names with the allele number in brackets. It is this combination of alleles that defines the sequence type.\n\n\n\n\nIn this example, our sequence type is ST=36. This is methicillin-resistant \nStaphylococcus aureus\n (or MRSA).\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-MLST-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe MLST analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Using MLST"
        }, 
        {
            "location": "/modules/mlst/#using-mlst-for-bacterial-typing", 
            "text": "A bacterial  type  is a particular species with certain features.   For example, the bacterial type may be  Staphyloccus aureus  with resistance to penicillin.  To  type  a bacteria, we can focus on several genes, and see which allele is present for each of these genes.  Each bacterial species will have its own scheme, which is the set of genes that are looked at.  Overall, this process is called multi-locus (= several genes) sequence typing, or MLST.   In this tutorial, we will perform MLST on a bacterial sequence.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Using MLST for bacterial typing"
        }, 
        {
            "location": "/modules/mlst/#get-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).   If you are using Galaxy Australia, look for the file we need in the  Shared Data .   In the top centre panel, go to  Shared Data  Click  Histories  Click on the history named  MLST-tutorial  Click  Import  (in the top right corner)  This should now be your current history.   Alternatively , we can get the sequence from Genbank.   In a new browser tab, go to this address:  https://www.ncbi.nlm.nih.gov/nuccore/NC_002952.2  Click  Send to  Choose  File  Choose  FASTA  Click  Create File   This downloads  sequence.fasta  to your computer.   In the tool panel, go to  Get Data -  Upload File   Choose local file : select  sequence.fasta  Start  Close   This file should now be in your History panel. When it has completed uploading, the file name will be green.", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/mlst/#run-mlst", 
            "text": "In the tool panel search box, search for MLST.   Click  MLST   The tool interface will appear in the centre Galaxy panel.   For  input_file , choose the sequence file that you uploaded, e.g.  sequence.fasta  Click  Execute", 
            "title": "Run MLST"
        }, 
        {
            "location": "/modules/mlst/#what-does-mlst-do", 
            "text": "Takes a fasta or genbank file  Scans this against all the typing schemes  Finds the best match (e.g. a scheme for the correct species)  Reports the output:  the scheme chosen  the sequence type (e.g. ST = 21)  the genes in this scheme and the alleles found in the data", 
            "title": "What does MLST do?"
        }, 
        {
            "location": "/modules/mlst/#view-results", 
            "text": "The results file will be at the top of your history panel.    Click on the eye icon to view the output.    Your results will be a single line.     For example:   Column 2: the scheme  Column 3: the sequence type  The rest of the columns: the gene names with the allele number in brackets. It is this combination of alleles that defines the sequence type.   In this example, our sequence type is ST=36. This is methicillin-resistant  Staphylococcus aureus  (or MRSA).", 
            "title": "View results"
        }, 
        {
            "location": "/modules/mlst/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-MLST-analysis  Click  Import  (at the top right corner)  The MLST analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/mlst/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/kraken/", 
            "text": "Sample identification with Kraken\n\n\nTo identify a sample from sequencing reads, we can use the tool \nKraken\n. This tool can also be used to identify members in a mixed set of reads, for metagenomics.\n\n\n\n\n\n\ne.g. reads from one sample \n Kraken \n 95% \nStaphylococcus aureus\n.\n\n\n\n\n\n\ne.g. mixed reads \n Kraken \n 50% \nStaphylococcus aureus\n, 40%  \nCampylobacter concisus\n, 10% unclassified.\n\n\n\n\n\n\n\n\n\nIn this tutorial we will use Kraken to confirm the identify of reads from a bacterial isolate.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nGet data\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nCreate a new history for this analysis.\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\n\n\n\n\nRight click on a  name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\n\n\nThe file name is quite long: let\ns change it:\n\n\n\n\nClick on the pencil icon next to the file name.\n\n\nIn the centre Galaxy panel, click in the box under \nName\n\n\nShorten the file name to, for example, \nstaph_R1.fastq\n\n\nThen click \nSave\n\n\n\n\nRepeat this for all the files on Zenodo. You should now have four files in your current history:\n\n\n\n\n\n\n\nRun Kraken\n\n\nWe have a sample that should be \nStaphylococcus aureus\n. The paired-end FASTQ read files are:\n\n\n\n\nstaph_R1.fq\n and \nstaph_R2.fq\n.\n\n\n\n\n(We will look at the other set of files later on in the tutorial).\n\n\n\n\n\n\nGo to \nTools\n search bar and type in \nKraken\n. Click on the \nKraken\n tool.  \n\n\n\n\n\n\nSet the following parameters:\n\n\n\n\nSingle or paired reads\n: \nPaired\n\n\nForward strand:\n \nstaph_R1.fq\n\n\nReverse strand:\n \nstaph_R2.fq\n\n\nSelect a Kraken database:\n \nMinikraken\n\n\nleave other settings as they are\n\n\nClick \nExecute\n\n\n\n\n\n\n\n\n\n\n\nExamine the output\n\n\nThe output is a file called \nKraken on data x and x: Classification\n. This will be at the top of your history pane.\n\n\nClick \nRefresh\n if the file hasn\nt yet turned green.\n\n\n\n\nWhen the file is green, click on the eye icon to view.\n\n\n\n\nWe will turn this output into something easier to read in the next step.\n\n\nColumn 2 is the sequence ID.\n\n\nColumn 3 is the taxon ID (from NCBI).\n\n\nColumn 5 is a summary of all the taxon IDs that each k-mer in the sequence matched to (taxon ID:number of k-mers).  \n\n\n\n\n\n\n\n\n\nKraken report\n\n\n\n\n\n\nGo to \nTools\n search bar and type in \nKraken-report\n. Click on the \nKraken-report\n tool.\n\n\n\n\n\n\nSet the following parameters:\n\n\n\n\nKraken output\n: \nKraken on data x and x: Classification\n\n\nSelect a Kraken database\n: \nMinikraken\n\n\nClick \nExecute\n\n\n\n\n\n\n\n\nThe output file is called \nKraken-report on data x\n.\n\n\n\n\nClick on the eye icon to view.\n\n\nColumn 1: percentage of reads in the clade/taxon in Column 6\n\n\nColumn 2: number of reads in the clade.\n\n\nColumn 3: number of reads in the clade but not further classified.\n\n\nColumn 4: code indicating the rank of the classification: (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, (S)pecies).\n\n\nColumn 5: NCBI taxonomy ID.\n\n\n\n\n\n\nApproximately 95% of reads were classified as \nStaphylococcus aureus\n, confirming the correct identity of our bacterial sample.\n\n\n\n\nOf these reads, roughly half were uniquely present in \nS. aureus\n subsp. \naureus\n, and most of those were uniquely present in strain HO 5096 0412.\n\n\nThe sample strain is therefore most related to the HO 5096 0412 strain.\n\n\n\n\nThe remaining reads within the \nS. aureus\n clade were classified into various taxa.\n\n\n\n\nScroll down column 3 to see the number of reads assigned directly to the taxon in column 6.\n\n\nThese are all very low and can be disregarded.\n\n\n\n\n\n\n\nNext\n\n\nRe-run Kraken with another sample. This sample should be \nEnterococcus faecalis\n.\n\n\n\n\nUse the files \nent_R1.fq\n and \nent_R2.fq\n.\n\n\nRun \nKraken\n with these files. These are paired-end reads.\n\n\nWith the \nClassification\n file from Kraken, run \nKraken-report\n.\n\n\nCick on the eye icon to view the \nKraken-report\n file.\n\n\n\n\n\n\n\n\n\n\n63% are classified to the genus \nEnterococcus\n, and most of these to \nE. faecalis\n.\n\n\n\n\n\n\nHowever, if we scroll down the table of results, we see that 31% are classified to the genus \nMycobacterium\n, mostly \nM. abscessus\n. These are not in the same phylum as \nEnterococcus\n.\n\n\n\n\n\n\n\n\n\n\nThis sample is probably contaminated.\n\n\n\n\nLinks\n\n\nKraken paper\n\n\nKraken software\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-kraken-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Sample identification"
        }, 
        {
            "location": "/modules/kraken/#sample-identification-with-kraken", 
            "text": "To identify a sample from sequencing reads, we can use the tool  Kraken . This tool can also be used to identify members in a mixed set of reads, for metagenomics.    e.g. reads from one sample   Kraken   95%  Staphylococcus aureus .    e.g. mixed reads   Kraken   50%  Staphylococcus aureus , 40%   Campylobacter concisus , 10% unclassified.     In this tutorial we will use Kraken to confirm the identify of reads from a bacterial isolate.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Sample identification with Kraken"
        }, 
        {
            "location": "/modules/kraken/#get-data", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Create a new history for this analysis.  In a new browser tab, go to this webpage:     Right click on a  name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.   The file name is quite long: let s change it:   Click on the pencil icon next to the file name.  In the centre Galaxy panel, click in the box under  Name  Shorten the file name to, for example,  staph_R1.fastq  Then click  Save   Repeat this for all the files on Zenodo. You should now have four files in your current history:", 
            "title": "Get data"
        }, 
        {
            "location": "/modules/kraken/#run-kraken", 
            "text": "We have a sample that should be  Staphylococcus aureus . The paired-end FASTQ read files are:   staph_R1.fq  and  staph_R2.fq .   (We will look at the other set of files later on in the tutorial).    Go to  Tools  search bar and type in  Kraken . Click on the  Kraken  tool.      Set the following parameters:   Single or paired reads :  Paired  Forward strand:   staph_R1.fq  Reverse strand:   staph_R2.fq  Select a Kraken database:   Minikraken  leave other settings as they are  Click  Execute", 
            "title": "Run Kraken"
        }, 
        {
            "location": "/modules/kraken/#examine-the-output", 
            "text": "The output is a file called  Kraken on data x and x: Classification . This will be at the top of your history pane.  Click  Refresh  if the file hasn t yet turned green.   When the file is green, click on the eye icon to view.   We will turn this output into something easier to read in the next step.  Column 2 is the sequence ID.  Column 3 is the taxon ID (from NCBI).  Column 5 is a summary of all the taxon IDs that each k-mer in the sequence matched to (taxon ID:number of k-mers).", 
            "title": "Examine the output"
        }, 
        {
            "location": "/modules/kraken/#kraken-report", 
            "text": "Go to  Tools  search bar and type in  Kraken-report . Click on the  Kraken-report  tool.    Set the following parameters:   Kraken output :  Kraken on data x and x: Classification  Select a Kraken database :  Minikraken  Click  Execute     The output file is called  Kraken-report on data x .   Click on the eye icon to view.  Column 1: percentage of reads in the clade/taxon in Column 6  Column 2: number of reads in the clade.  Column 3: number of reads in the clade but not further classified.  Column 4: code indicating the rank of the classification: (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, (S)pecies).  Column 5: NCBI taxonomy ID.    Approximately 95% of reads were classified as  Staphylococcus aureus , confirming the correct identity of our bacterial sample.   Of these reads, roughly half were uniquely present in  S. aureus  subsp.  aureus , and most of those were uniquely present in strain HO 5096 0412.  The sample strain is therefore most related to the HO 5096 0412 strain.   The remaining reads within the  S. aureus  clade were classified into various taxa.   Scroll down column 3 to see the number of reads assigned directly to the taxon in column 6.  These are all very low and can be disregarded.", 
            "title": "Kraken report"
        }, 
        {
            "location": "/modules/kraken/#next", 
            "text": "Re-run Kraken with another sample. This sample should be  Enterococcus faecalis .   Use the files  ent_R1.fq  and  ent_R2.fq .  Run  Kraken  with these files. These are paired-end reads.  With the  Classification  file from Kraken, run  Kraken-report .  Cick on the eye icon to view the  Kraken-report  file.      63% are classified to the genus  Enterococcus , and most of these to  E. faecalis .    However, if we scroll down the table of results, we see that 31% are classified to the genus  Mycobacterium , mostly  M. abscessus . These are not in the same phylum as  Enterococcus .      This sample is probably contaminated.", 
            "title": "Next"
        }, 
        {
            "location": "/modules/kraken/#links", 
            "text": "Kraken paper  Kraken software", 
            "title": "Links"
        }, 
        {
            "location": "/modules/kraken/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-kraken-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/kraken/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/dge/", 
            "text": "RNA-Seq: Bacteria\n\n\nThis tutorial is about using RNA-seq data to investigate differential gene expression in bacteria, using Galaxy tools and Degust (a tool on the web).\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\n\n\n\nBackground\n\n\nDifferential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.\n\n\n\n\n\nInput data: reads and reference\n\n\nRNA-Seq reads\n\n\nA typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.\n\n\n\n\nOur RNA-seq reads are from 6 samples in \nFASTQ\n format.\n\n\nWe have single-end reads; so one file per sample.\n\n\nData could also be paired-end reads, and there would be two files per sample.\n\n\n\n\n\n\nThese have been reduced to 1% of their original size for this tutorial.\n\n\nThe experiment used the bacteria \nE. coli\n grown in two conditions.\n\n\nFiles labelled \nLB\n are the wildtype\n\n\nFiles labelled \nMG\n have been exposed to 0.5% \nMG - alpha methyglucoside (a sugar solution).\n\n\n\n\n\n\n\n\n\n\n\nReference genome\n\n\nThe reference genomes is in \nFASTA\n format and the gene annotations are in \nGTF\n format.\n\n\n\n\nThe \nFASTA\n file contains the DNA sequence(s) that make up the genome; e.g. the chromosome and any plasmids.\n\n\nThe \nGTF\n file lists the coordinates (position) of each feature. Commonly-annotated features are genes, transcripts and protein-coding sequences.\n\n\n\n\n\n\n\nUpload files to Galaxy\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nCreate a new history for this analysis.\n\n\n\n\nIf you are using Galaxy Australia:\n\n\n\n\nGo to \nShared Data: Data Libraries\n.\n\n\nClick on \nRNA-Seq-data\n, then Import.\n\n\nThe files should now be in your current history.\n\n\n\n\n\n\nAlternatively\n, you can obtain the data from Zenodo:\n\n\n\n\nIn a new browser tab, go to this webpage:\n\n\n\n\nFor each file, right click on file name: select \ncopy link address\n\n\nIn Galaxy, go to \nGet Data\n and then Upload File\n\n\nClick \nPaste/Fetch data\n\n\nA box will appear: paste in link address\n\n\nClick \nStart\n\n\nClick \nClose\n\n\nThe file will now appear in the top of your history panel.\n\n\nRepeat for all files in Zenodo.\n\n\nChange (shorten) the file names with the pencil icon.\n\n\n\n\n\n\n\n\n\n\nAlign reads to reference\n\n\nThe RNA-Seq reads are fragmented and are not complete transcripts. To determine the transcripts from which the reads originated (and therefore, to which gene they correspond) we can map them to a reference genome.\n\n\nIn Galaxy:\n\n\n\n\nIn the \nTools\n panel, search for \nMap with BWA-MEM\n and click on it.\n\n\nUnder \nWill you select a reference genome from your history or use a built-in index?\n: \nUse a genome from history and build index\n\n\nUse the following dataset as the reference sequence\n: \nEcoli_k12.fasta\n\n\nSingle or Paired-end reads\n: \nsingle\n\n\nSelect fastq dataset\n:\n\n\nClick on the \nMultiple Datasets\n icon in centre\n\n\nSelect all 6 \nFASTQ\n files (they turn blue; use side-scroll bar to check all have been selected)\n\n\nThis will map each set of reads to the reference genome\n\n\n\n\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\nClick \nRefresh\n in the history pane to see if the analysis has finished.\n\n\n\n\nOutput: 6 \nbam\n files of reads mapped to the reference genome.\n\n\n\n\n\n\nRe-name the output files:\n\n\n\n\nThese are called \nMap with BWA-MEM on data x and data x\n.\n\n\nThe x will refer to the numbered file that Galaxy used in the analysis.\n\n\nClick on the pencil icon next to each of these and re-name them as their sample name (e.g. LB1, LB2 etc.).\n\n\n\n\n\n\n\n\nCount reads per gene\n\n\nWe now need to count how many reads overlap with particular genes. The information about gene names is from the annotations in the GTF file.\n\n\nIn Galaxy:\n\n\n\n\nIn the \nTools\n panel, search for \ncount matrix\n and click on \nSAM/BAM to count matrix\n\n\nNote: Don\nt select the tool called \nhtseq-count\n. The \nSAM/BAM to count matrix\n also uses that tool but allows an input of multiple bam files, which is what we want.\n\n\n\n\n\n\nFor \nGene model (GFF) file to count reads over from your current history\n, select the \nGTF\n file.\n\n\nFor \nReads are stranded\n select \nYes\n (box turns dark grey)\n\n\nFor \nGTF feature type for counting reads\n select \ntranscript\n.\n\n\nFor \nbam/sam file from your history\n choose the 6 \nbam\n files.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n\n\nClick \nRefresh\n in the history pane to see if the analysis has finished.\n\n\n\n\nOutput:\n\n\n\n\nThere is one output file: \nbams to DGE count matrix\n.\n\n\nClick on the file name to expand the information in the History pane.\n\n\nClick on the file \nicon underneath to download it to your computer for use later on in this tutorial.\n\n\nClick on the eye icon to see this file.\n\n\n\n\n\n\n\n\nEach row is a gene (or feature) and each column is a sample, with counts against each gene.\n\n\nHave a look at how the counts vary between samples, per gene.\n\n\nWe can\nt just compare the counts directly; they need to be normalized before comparison, and this will be done as part of the DGE analysis in the next step.\n\n\n\n\nDGE in Degust\n\n\nDegust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.\n\n\n(Degust can also display the results from DGE analyses performed elsewhere.)\n\n\nUpload counts file\n\n\nGo to the \nDegust web page\n.\n\n\n\n\nClick \nUpload your counts file\n.\n\n\nClick on \nChoose File\n.\n\n\nSelect the \nhtseq output file. tabular\n (that you previously downloaded to your computer from Galaxy) and click \nOpen\n. This file may have a different name, for example, it may have \nGalaxy\n in the title.\n\n\nClick \nUpload\n.\n\n\n\n\nA Configuation page will appear.\n\n\n\n\nFor \nName\n type \nDGE in E coli\n\n\nFor \nInfo columns\n select \nContig\n\n\nFor \nAnalyze server side\n leave box checked.\n\n\nFor \nMin gene read count\n put \n10\n.\n\n\nClick \nAdd condition\n\n\nAdd a condition called \nControl\n and select the LB columns.\n\n\nAdd a condition called \nTreament\n and select the MG columns.\n\n\n\n\n\n\nSave changes\n\n\nView\n - this brings up the Degust viewing window.\n\n\n\n\nOverview of Degust sections\n\n\n\n\nTop black panel with \nConfigure\n settings at right.\n\n\nLeft: Conditions: Control and Treatment.\n\n\nLeft: Method selection for DGE.\n\n\nTop centre: Plots, with options at right.\n\n\nWhen either of the expression plots are selected, a heatmap appears below.\n\n\nA table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).  \n\n\n\n\n\n\nAnalyze gene expression\n\n\n\n\nUnder \nMethod\n, make sure that \nVoom/Limma\n is selected.\n\n\nClick \nApply\n. This runs Voom/Limma on the uploaded counts.\n\n\n\n\nMDS plot\n\n\nFirst, look at the MDS plot.\n\n\n\n\n\n\nThis is a multidimensional scaling plot which represents the variation between samples.\n\n\nIdeally:\n\n\nAll the LB samples would be close to each other\n\n\nAll the MG samples would be close to each other\n\n\nThe LB and MG groups would be far apart\n\n\n\n\n\n\nThe x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.\n\n\nOur LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.\n\n\n\n\nExpression - MA plot\n\n\nEach dot shows the change in expression in one gene.\n\n\n\n\nThe average expression (over both condition and treatment samples) is represented on the x-axis.\n\n\nPlot points should be symmetrical around the x-axis.\n\n\nWe can see that many genes are expressed at a low level, and some are highly expressed.\n\n\n\n\n\n\nThe fold change is represented on the y axis.\n\n\nIf expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR \n0.05).\n\n\nAt low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.\n\n\n\n\n\n\n\n\nClick on the dot to see the gene name.     \n\n\n\n\nExpression - Parallel Coordinates and heatmap\n\n\nEach line shows the change in expression in one gene, between control and treatment.\n\n\n\n\nGo to \nOptions\n at the right.\n\n\nFor \nFDR cut-off\n set at 0.001.\n\n\nThis is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.\n\n\n\n\n\n\n\n\nLook at the Parallel Coordinates plot. There are two axes:\n\n\n\n\nLeft: \nControl\n: Gene expression in the control samples. All values are set at zero.\n\n\nRight: \nTreatment\n Gene expression in the treatment samples, relative to expression in the control.\n\n\n\n\n\n\n\n\nThe blocks of blue and red underneath the plot are called a heatmap.\n\n\n\n\nEach block is a gene. Click on a block to see its line in the plot above.\n\n\nLook at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\nfor an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).\n\n\n\n\nTable of genes\n\n\n\n\nContig\n: names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).\n\n\nFDR\n: False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.\n\n\nControl\n and \nTreatment\n: log2(Fold Change) of gene expression. The default display is of fold change in the treatment relative to the control. Therefore, values in the \nControl\n column are zero. This can be changed in the \nOptions\n panel at the top right.\n\n\nIn some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.\n\n\n\n\nTable of genes and expression:\n\n\n\n\n\n\n\nDGE in Galaxy\n\n\nDifferential gene expression can also be analyzed in Galaxy. The input is the count matrix produced by a tool such as HTSeq-Count (see section above: \nCount reads per gene\n).\n\n\n\n\nIn the \nTools\n panel, search for \nDifferential_Count models\n (don\nt forget the underscore) and click on it.\n\n\nThis has options to use edgeR, DESeq, or Voom. Here we will use Voom.\n\n\n\n\n\n\nFor \nSelect an input matrix\n choose the \ncount matrix\n file generated in the previous step.\n\n\nFor \nTitle for job outputs\n enter \nDGE using voom\n.\n\n\nFor \nSelect columns containing treatment\n tick boxes for the MG samples.\n\n\nFor \nSelect columns containing control\n tick boxes for the LB samples.\n\n\nUnder \nRun this model using edgeR\n choose \nDo not run edgeR\n.\n\n\nUnder \nRun the same model with DESeq2 and compare findings\n choose \nDo not run DESeq2\n.\n\n\nUnder \nRun the same model with Voom/limma and compare findings\n choose \nRun VOOM\n.\n\n\n\n\nYour tool interface should look like this:\n\n\n\n\n\n\nClick \nExecute\n.\n\n\n\n\nThere are two output files.\n\n\nView the file called \nDGEusingvoom.html\n.\n\n\n\n\nScroll down to \nVOOM log output\n and \n#VOOM top 50\n.\n\n\nThe \nContig\n column has the gene names.\n\n\nLook at the \nadj.P.Val\n column. This is an adjusted p value to show the significance of the gene expression difference, accounting for the effect of multiple testing. Also known as False Discovery Rate. The table is ordered by the values in this column.\n\n\nLook at the \nlogFC\n column. This is log2(Fold Change) of relative gene expression between the treatment samples and the control samples.\n\n\n\n\nView the file called \nDEGusingvoom_topTable_VOOM.xls\n.\n\n\n\n\n\n\nThis is a list of all the genes that had transcripts mapped, and associated statistics.\n\n\n\n\n\n\nLink to Voom paper.\n\n\n\n\n\n\nInvestigate differentially-expressed genes\n\n\nTo learn more about the differentially-expressed genes:\n\n\n\n\nGo to \nthe NCBI website.\n\n\nUnder \nAll Databases\n, click on \nGene\n\n\nEnter the gene name in the search bar; e.g. ptsG\n\n\nClick on the first result that matches the species (e.g. in this case, \nE. coli\n).\n\n\nThis provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).\n\n\n\n\n\n\n\n\nSome of the most (statistically) significant differentially-expressed genes in this experiment are:\n\n\n\n\nptsG\n: a glucose-specific transporter.\n\n\nsetA\n: a sugar efflux transporter; is induced by glucose-phosphate stress.\n\n\nsucD\n: the alpha subunit of the the gene for succinyl-CoA synthetase; involved in ATP production.\n\n\nsucB\n: a component of the 2-oxoglutarate dehydrogenase complex; catalyzes a step in the Krebs cycle.\n\n\ndeoC\n: 2-deoxyribose-5-phosphate aldolase; binds selenium; may be involved in selenium transport.\n\n\n\n\n\n\n\nSee this history in Galaxy\n\n\nIf you want to see this Galaxy history without performing the steps above:\n\n\n\n\nLog in to Galaxy Australia: \nhttps://usegalaxy.org.au/\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-RNA-seq-bacteria\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "RNA-seq - bacteria"
        }, 
        {
            "location": "/modules/dge/#rna-seq-bacteria", 
            "text": "This tutorial is about using RNA-seq data to investigate differential gene expression in bacteria, using Galaxy tools and Degust (a tool on the web).  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "RNA-Seq: Bacteria"
        }, 
        {
            "location": "/modules/dge/#background", 
            "text": "Differential Gene Expression (DGE) is the process of determining whether any genes were expressed at a different level between two conditions. For example, the conditions could be wildtype versus mutant, or two growth conditions. Usually multiple biological replicates are done for each condition - these are needed to separate variation within the condition from that between the conditions.", 
            "title": "Background"
        }, 
        {
            "location": "/modules/dge/#input-data-reads-and-reference", 
            "text": "RNA-Seq reads  A typical experiment will have 2 conditions each with 3 replicates, for a total of 6 samples.   Our RNA-seq reads are from 6 samples in  FASTQ  format.  We have single-end reads; so one file per sample.  Data could also be paired-end reads, and there would be two files per sample.    These have been reduced to 1% of their original size for this tutorial.  The experiment used the bacteria  E. coli  grown in two conditions.  Files labelled  LB  are the wildtype  Files labelled  MG  have been exposed to 0.5%  MG - alpha methyglucoside (a sugar solution).      Reference genome  The reference genomes is in  FASTA  format and the gene annotations are in  GTF  format.   The  FASTA  file contains the DNA sequence(s) that make up the genome; e.g. the chromosome and any plasmids.  The  GTF  file lists the coordinates (position) of each feature. Commonly-annotated features are genes, transcripts and protein-coding sequences.    Upload files to Galaxy   Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Create a new history for this analysis.   If you are using Galaxy Australia:   Go to  Shared Data: Data Libraries .  Click on  RNA-Seq-data , then Import.  The files should now be in your current history.    Alternatively , you can obtain the data from Zenodo:   In a new browser tab, go to this webpage:   For each file, right click on file name: select  copy link address  In Galaxy, go to  Get Data  and then Upload File  Click  Paste/Fetch data  A box will appear: paste in link address  Click  Start  Click  Close  The file will now appear in the top of your history panel.  Repeat for all files in Zenodo.  Change (shorten) the file names with the pencil icon.", 
            "title": "Input data: reads and reference"
        }, 
        {
            "location": "/modules/dge/#align-reads-to-reference", 
            "text": "The RNA-Seq reads are fragmented and are not complete transcripts. To determine the transcripts from which the reads originated (and therefore, to which gene they correspond) we can map them to a reference genome.  In Galaxy:   In the  Tools  panel, search for  Map with BWA-MEM  and click on it.  Under  Will you select a reference genome from your history or use a built-in index? :  Use a genome from history and build index  Use the following dataset as the reference sequence :  Ecoli_k12.fasta  Single or Paired-end reads :  single  Select fastq dataset :  Click on the  Multiple Datasets  icon in centre  Select all 6  FASTQ  files (they turn blue; use side-scroll bar to check all have been selected)  This will map each set of reads to the reference genome     Your tool interface should look like this:    Click  Execute  Click  Refresh  in the history pane to see if the analysis has finished.   Output: 6  bam  files of reads mapped to the reference genome.    Re-name the output files:   These are called  Map with BWA-MEM on data x and data x .  The x will refer to the numbered file that Galaxy used in the analysis.  Click on the pencil icon next to each of these and re-name them as their sample name (e.g. LB1, LB2 etc.).", 
            "title": "Align reads to reference"
        }, 
        {
            "location": "/modules/dge/#count-reads-per-gene", 
            "text": "We now need to count how many reads overlap with particular genes. The information about gene names is from the annotations in the GTF file.  In Galaxy:   In the  Tools  panel, search for  count matrix  and click on  SAM/BAM to count matrix  Note: Don t select the tool called  htseq-count . The  SAM/BAM to count matrix  also uses that tool but allows an input of multiple bam files, which is what we want.    For  Gene model (GFF) file to count reads over from your current history , select the  GTF  file.  For  Reads are stranded  select  Yes  (box turns dark grey)  For  GTF feature type for counting reads  select  transcript .  For  bam/sam file from your history  choose the 6  bam  files.   Your tool interface should look like this:    Click  Execute  Click  Refresh  in the history pane to see if the analysis has finished.   Output:   There is one output file:  bams to DGE count matrix .  Click on the file name to expand the information in the History pane.  Click on the file  icon underneath to download it to your computer for use later on in this tutorial.  Click on the eye icon to see this file.     Each row is a gene (or feature) and each column is a sample, with counts against each gene.  Have a look at how the counts vary between samples, per gene.  We can t just compare the counts directly; they need to be normalized before comparison, and this will be done as part of the DGE analysis in the next step.", 
            "title": "Count reads per gene"
        }, 
        {
            "location": "/modules/dge/#dge-in-degust", 
            "text": "Degust is a tool on the web that can analyse the counts files produced in the step above, to test for differential gene expression.  (Degust can also display the results from DGE analyses performed elsewhere.)", 
            "title": "DGE in Degust"
        }, 
        {
            "location": "/modules/dge/#upload-counts-file", 
            "text": "Go to the  Degust web page .   Click  Upload your counts file .  Click on  Choose File .  Select the  htseq output file. tabular  (that you previously downloaded to your computer from Galaxy) and click  Open . This file may have a different name, for example, it may have  Galaxy  in the title.  Click  Upload .   A Configuation page will appear.   For  Name  type  DGE in E coli  For  Info columns  select  Contig  For  Analyze server side  leave box checked.  For  Min gene read count  put  10 .  Click  Add condition  Add a condition called  Control  and select the LB columns.  Add a condition called  Treament  and select the MG columns.    Save changes  View  - this brings up the Degust viewing window.", 
            "title": "Upload counts file"
        }, 
        {
            "location": "/modules/dge/#overview-of-degust-sections", 
            "text": "Top black panel with  Configure  settings at right.  Left: Conditions: Control and Treatment.  Left: Method selection for DGE.  Top centre: Plots, with options at right.  When either of the expression plots are selected, a heatmap appears below.  A table of genes (or features); expression in treatment relative to control (Treatment column); and significance (FDR column).", 
            "title": "Overview of Degust sections"
        }, 
        {
            "location": "/modules/dge/#analyze-gene-expression", 
            "text": "Under  Method , make sure that  Voom/Limma  is selected.  Click  Apply . This runs Voom/Limma on the uploaded counts.", 
            "title": "Analyze gene expression"
        }, 
        {
            "location": "/modules/dge/#mds-plot", 
            "text": "First, look at the MDS plot.    This is a multidimensional scaling plot which represents the variation between samples.  Ideally:  All the LB samples would be close to each other  All the MG samples would be close to each other  The LB and MG groups would be far apart    The x-axis is the dimension with the highest magnitude. The control/treatment samples should be split along this axis.  Our LB samples are on the left and the MG samples are on the right, which means they are well separated on their major MDS dimension, which looks correct.", 
            "title": "MDS plot"
        }, 
        {
            "location": "/modules/dge/#expression-ma-plot", 
            "text": "Each dot shows the change in expression in one gene.   The average expression (over both condition and treatment samples) is represented on the x-axis.  Plot points should be symmetrical around the x-axis.  We can see that many genes are expressed at a low level, and some are highly expressed.    The fold change is represented on the y axis.  If expression is significantly different between treatment and control, the dots are red. If not, they are blue. (In Degust, significant means FDR  0.05).  At low levels of gene expression (low values of the x axis), fold changes are less likely to be significant.     Click on the dot to see the gene name.", 
            "title": "Expression - MA plot"
        }, 
        {
            "location": "/modules/dge/#expression-parallel-coordinates-and-heatmap", 
            "text": "Each line shows the change in expression in one gene, between control and treatment.   Go to  Options  at the right.  For  FDR cut-off  set at 0.001.  This is a significance level (an adjusted p value). We will set it quite low in this example, to ensure we only examine key differences.     Look at the Parallel Coordinates plot. There are two axes:   Left:  Control : Gene expression in the control samples. All values are set at zero.  Right:  Treatment  Gene expression in the treatment samples, relative to expression in the control.     The blocks of blue and red underneath the plot are called a heatmap.   Each block is a gene. Click on a block to see its line in the plot above.  Look at the row for the Treatment. Relative to the control, genes expressed more are red; genes expressed less are blue.      Note:   for an experiment with multiple treatments, the various treatment axes can be dragged to rearrange. There is no natural order (such as a time series).", 
            "title": "Expression - Parallel Coordinates and heatmap"
        }, 
        {
            "location": "/modules/dge/#table-of-genes", 
            "text": "Contig : names of genes. Note that gene names are sometimes specific to a species, or they may be only named as a locus ID (a chromosomal location specified in the genome annotation).  FDR : False Discovery Rate. This is an adjusted p value to show the significance of the difference in gene expression between two conditions. Click on column headings to sort. By default, this table is sorted by FDR.  Control  and  Treatment : log2(Fold Change) of gene expression. The default display is of fold change in the treatment relative to the control. Therefore, values in the  Control  column are zero. This can be changed in the  Options  panel at the top right.  In some cases, a large fold change will be meaningful but in others, even a small fold change can be important biologically.   Table of genes and expression:", 
            "title": "Table of genes"
        }, 
        {
            "location": "/modules/dge/#dge-in-galaxy", 
            "text": "Differential gene expression can also be analyzed in Galaxy. The input is the count matrix produced by a tool such as HTSeq-Count (see section above:  Count reads per gene ).   In the  Tools  panel, search for  Differential_Count models  (don t forget the underscore) and click on it.  This has options to use edgeR, DESeq, or Voom. Here we will use Voom.    For  Select an input matrix  choose the  count matrix  file generated in the previous step.  For  Title for job outputs  enter  DGE using voom .  For  Select columns containing treatment  tick boxes for the MG samples.  For  Select columns containing control  tick boxes for the LB samples.  Under  Run this model using edgeR  choose  Do not run edgeR .  Under  Run the same model with DESeq2 and compare findings  choose  Do not run DESeq2 .  Under  Run the same model with Voom/limma and compare findings  choose  Run VOOM .   Your tool interface should look like this:    Click  Execute .   There are two output files.  View the file called  DGEusingvoom.html .   Scroll down to  VOOM log output  and  #VOOM top 50 .  The  Contig  column has the gene names.  Look at the  adj.P.Val  column. This is an adjusted p value to show the significance of the gene expression difference, accounting for the effect of multiple testing. Also known as False Discovery Rate. The table is ordered by the values in this column.  Look at the  logFC  column. This is log2(Fold Change) of relative gene expression between the treatment samples and the control samples.   View the file called  DEGusingvoom_topTable_VOOM.xls .    This is a list of all the genes that had transcripts mapped, and associated statistics.    Link to Voom paper.", 
            "title": "DGE in Galaxy"
        }, 
        {
            "location": "/modules/dge/#investigate-differentially-expressed-genes", 
            "text": "To learn more about the differentially-expressed genes:   Go to  the NCBI website.  Under  All Databases , click on  Gene  Enter the gene name in the search bar; e.g. ptsG  Click on the first result that matches the species (e.g. in this case,  E. coli ).  This provides information about the gene, and may also show further references (e.g. in this case, a link to the EcoGene resource).     Some of the most (statistically) significant differentially-expressed genes in this experiment are:   ptsG : a glucose-specific transporter.  setA : a sugar efflux transporter; is induced by glucose-phosphate stress.  sucD : the alpha subunit of the the gene for succinyl-CoA synthetase; involved in ATP production.  sucB : a component of the 2-oxoglutarate dehydrogenase complex; catalyzes a step in the Krebs cycle.  deoC : 2-deoxyribose-5-phosphate aldolase; binds selenium; may be involved in selenium transport.", 
            "title": "Investigate differentially-expressed genes"
        }, 
        {
            "location": "/modules/dge/#see-this-history-in-galaxy", 
            "text": "If you want to see this Galaxy history without performing the steps above:   Log in to Galaxy Australia:  https://usegalaxy.org.au/  Go to  Shared Data  Click  Histories  Click  Completed-RNA-seq-bacteria  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.", 
            "title": "See this history in Galaxy"
        }, 
        {
            "location": "/modules/dge/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/rna-humans/", 
            "text": "RNA-seq: Humans\n\n\nnot yet updated for Galaxy Australia\n\n\nBasic\n\n\nhttps://www.melbournebioinformatics.org.au/tutorials/tutorials/rna_seq_dge_basic/rna_seq_basic_tutorial/\n\n\nAdvanced\n\n\nhttps://www.melbournebioinformatics.org.au/tutorials/tutorials/rna_seq_dge_advanced/rna_seq_advanced_tutorial/", 
            "title": "RNA-seq - humans"
        }, 
        {
            "location": "/modules/rna-humans/#rna-seq-humans", 
            "text": "not yet updated for Galaxy Australia", 
            "title": "RNA-seq: Humans"
        }, 
        {
            "location": "/modules/rna-humans/#basic", 
            "text": "https://www.melbournebioinformatics.org.au/tutorials/tutorials/rna_seq_dge_basic/rna_seq_basic_tutorial/", 
            "title": "Basic"
        }, 
        {
            "location": "/modules/rna-humans/#advanced", 
            "text": "https://www.melbournebioinformatics.org.au/tutorials/tutorials/rna_seq_dge_advanced/rna_seq_advanced_tutorial/", 
            "title": "Advanced"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/", 
            "text": "Metagenomics\n\n\nIn development\n\n\nBased on material by QFAB\n http.qfab.org\n\n\nTutorial Overview\n\n\nIn this tutorial we cover the concepts of metagenomics analysis in 16S rRNA.\n\n\nWhat\u2019s not covered:\n\n\nThis introductory tutorial covers the steps required for the first part of a 16S rRNA metagenomics study applied to samples from a single site. As such we only show analyses that can be applied to a single environment, that is, identifying what organisms are in your sample (diversity), and how many organisms there are in the sample (richness). Similar same steps would be applied if you had samples from multiple sites, with additional analyses that can compare the diversity and richness between samples. The latter part is not covered by this tutorial.\n\n\nBackground\n\n\n16S rRNA sequencing\n\n\nThe application of culture-independent rRNA-based phylogenetics to the study of bacterial diversity was first explored by researchers in the 1980s e.g. [2] and was used by Carl Woese to delineate the main branches of life [1]. These rRNA based analyses remain central methods in microbiology both for the exploration of species diversity but also or the application in bacterial identification.\n\n\nThe development of pyrosequencing technologies and the emergence of next generation DNA sequencing have changed the scales at which scientists can systematically survey the 16S rRNA content of biological samples and has been a key driver behind initiatives such as the human microbiome project [5].\n\n\nIn the broadest sense, 16S rRNA sequencing should not be confused with metagenomics which has been defined as \nthe application of shotgun sequencing to DNA obtained directly from an environmental sample or series of related samples, producing at least 50Mbp of randomly sampled sequence data\n [3] This is also in contrast to functional metagenomics whereby environmental DNA is first cloned and subsequently screened for specific functional activities e.g. [4]. Kunin et al elegantly argue that 16S rRNA profiling should in fact exist as a mandatory \nPremetagenome community composition profiling\n step in more comprehensive surveys [3]. There is discussion and debate as to how deep this sequencing could be performed but at JGI at least, a single 384 well plate is routinely surveyed.\n\n\nIrrespective of the nuances of terminology, metagenomics is a baseline technology for understanding the ecology and evolution of microbial ecosystems upon which hypotheses and experimental strategies are built.\n\n\nExperimental design is key\n\n\nMost 16S strategies are biased towards the measurement of bacterial and archaeal constituents of the environment and eukaryotes (e.g. fungi and protists) are excluded. This compromises the ability to measure the whole ecological spectrum of a microbial community; the larger and non-coding and thus uninterpretable parts of the eukaryotic genome are problematic. This is largely driving strategies that encompass additional metatranscriptomics surveys. The studies are thus oriented towards the sequence-tractable bacterial, archaeal and viral components of the research community.\n\n\nLimitations of the 16S rRNA profiling strategy\n\n\nThe 16S rRNA gene copy number of variable between bacterial species and this is further confounded by PCR amplification biases which skew estimates of the community composition.\n\n\nGoals\n\n\nThe goal of the 16S study is to understand the complexity of the community being sampled. This is assessed as a function of the number of species in the community (richness) and their relative abundances (evenness).\n\n\nThe workflow in Galaxy\n\n\nThe process presented in this workshop is aimed to be an introduction for molecular biologists to 16S rRNA metagenomics analysis. The workflow is also implemented such that it can be run using a standard desktop or laptop environment without the requirements of a large cluster or cloud infrastructure.\n\n\nThe steps are:\n\n\nDereplicate reads\nCluster reads into Operational Taxonomic Units (OTU)\nChimera detection and removal\nOTU Table\nPhylogenetic Tree alignment\nRarefaction analysis\nCollector Curve analysis\n\n\nFigure 1:\n\n\n\n\nWe will also perform an extra step where we visualize the taxa present in the sample, using the tool Krona.\n\n\nWhere is the data in this tutorial from?\n\n\nWe use the same data from the \nMothur Marine community analysis\n, that is  the study from the \nGlobal Ocean Sampling (GOS) Expedition\n. However we only concentrate on one site as opposed to the 14 sites they sampled.\n\n\nPreparation\n\n\nOpen a browser and go to your Galaxy server, for example, Galaxy Australia: usegalaxy.org.au\n\n\nImport the data\n\n\nIn Galaxy, go to \nShared Data\n and then \nData Libraries\n.\n\n\n\n\nSearch for \nMetagenomics 16S rRNA Data\n and click on it.\n\n\nTick the box next to the three files and then click the \nTo History\n button, and select \nas Datasets\n.\n\n\nName a new history and click \nImport\n\n\nThese three files should now be in your current history.\n\n\n\n\nClick on the eye icon on the top right of each fasta file to view the first part of the file.\n\n\nAlternative way to import data\n\n\nDownload the data directly to your computer using these URLs, then upload to Galaxy:\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Metagenomics_BASIC/seqs.fasta\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Metagenomics_BASIC/gold.fasta\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Metagenomics_BASIC/core_set_aligned.fasta\n\n\n\n\nOnce files are downloaded, in Galaxy click on \nGet data\nUpload File\n\n\nClick \nChoose local file\n, locate the local copy of each of the three fasta files and upload.\n\n\nYou can leave File Format as Auto-detect, or if you prefer, set it to fasta.\n\n\nClick \nStart\n and wait for the files to upload to Galaxy. It can take a couple of minutes.\n\n\n\n\nKeep only the unique reads\n\n\nThe aim here is to reduce the number of reads in the input file into clusters of identical sequences.\n\n\nDereplicate\n\n\nIn the tool panel (left hand side) search for the \nDereplicate\n tool and click on it.\n\n\n\n\nFor \nInput sequence file\n select the \nseqs.fasta\n dataset\n\n\nFor \nCriteria used for duplicate detection\n select \nFull length\n\n\n\n\nThere are two possible modes in the dereplication tool:\n(1) \nfull-length\n where the full length of the two sequences must be identical before being grouped together or\n(2) \nprefix\n where the first section of the two sequences are identical\n\n\n\n\nClick on \nExecute\n\n\n\n\nOutput\n\n\nClick on the name of the job \nDereplicate on data XX\n in the History panel (right hand side) and you will see the number of sequences have been reduced from 1,472 in the input data \nseqs.fasta\n to 1,459 sequences.\n\n\nExamine the output by clicking on the eye icon  in the top right hand corner of this step.\n\n\n\n\n\n\nNOTE: The size=XXXX annotation in the id line of the fasta file indicates the number of reads that were exactly the same as this representative sequence.\n\n\n\n\n\n\n(OPTIONAL) You can rename the output by clicking on the pencil icon  on the top right hand corner of the output. Click on the \u201cAttributes tab\u201d and then  type in a new name in the \u201cName\u201d field and click on Save.\n\n\n\n\n\n\nCluster sequences into groups\n\n\nThe aim here is to cluster the output from Step 1 into groups of sequences that are 97% similar to each other.\n\n\n\n\nSimilar sequences are assumed to belong to the same taxonomic groups. * These groups are known as Operational Taxonomic Units (OTUs) and the number of clusters that result are indicative of the number of species that are present in this sample.\n\n\n\n\nCluter OTUs\n\n\nIn the tool panel on the left hand side, search for the \nCluster OTU\n tool.\n\n\n\n\nFor \nInput sequence file\n, select the output from Step 1: \n Dereplicate on data XX\n\n\nFor \nMinimum cluster radius\n, enter 0.97. This value corresponds to 97% sequence identity.\n\n\nClick on \nExecute\n\n\n\n\nOutput\n\n\nClick on the name of the job \nCluster OTU on data 4\n in the History panel (right hand side) and you will find that the number of sequences has decreased to 559 sequences.\n\n\n\n\nExamine the output by clicking on the eye icon  in the top right hand corner of this step.\n\n\nThe output file is in Fasta format where each sequence is the representative of an OTU.\n\n\nFigure 2 below, provides a summary of the clustering approach. Reads are represented by solid dots. Those that are 97% similar to each other are grouped together into an OTU as represented by the blue dashed circles.\n\n\nIn this example, there are 3 OTUs. The reads that represents the centroid of each cluster are shown as red dots and these red dots form the representative of the corresponding OTU. These are the sequences that are reported in the output file. In this tutorial, the output file has 559 sequences, meaning that 559 OTUs were identified.\n\n\nNOTE: The number of sequences that you have may not be exactly the same as mentioned here. This is so as the clustering process starts by randomly selecting a read as the center of a cluster (see figure below). Since this is a random selection, each time you perform a clustering process, a different read can be selected and thus affect the end result.\n\n\n\n\nFor more detailed description of the OTU clustering algorithm, click \nhere\n.\n\n\nFigure 2.\n\n\n\n\nPlease Note: The \u201csize=XX\u201d annotation in the identifier line is NOT the number of sequences that is in the corresponding cluster (OTU). This value is the same as the input file.\n\n\nRemove chimeras\n\n\nThe aim here is to: identify and filter chimeric sequences utilizing a reference dataset containing nucleotide sequences believed to be free of chimeras.\n\n\nUchime\n\n\nIn the tool panel on the left hand side, search for the \nUchime\n tool.\n\n\n\n\nFor \nMode to detect chimeras\n, select \u201cref\u201d (reference mode).\n\n\n\n\nThere are two possible modes in the Uchime tool for chimera detection: (1) \nref\n where a reference dataset of parent sequences believed to be chimera-free is provided by the user or (2) \nde-novo\n where a database is constructed from the query sequences by using the abundance data.\n\n\n\n\nFor the second field \nInput reference file\n select the \nCluster OTU on data XX\n\n\nFor the third  field \nReference Database\n, select the \ngold.fasta\n. This file (downloaded from http://drive5.com/uchime/gold.fa) contains nucleotide sequences believed to be free of chimeras.\n\n\nClick on \nExecute\n\n\n\n\nOutput\n\n\n\n\n\n\nClick on \nUchime on data XX and data XX:chimeras\n\n\n\n\nThese sequences have been classified to be chimeras\n\n\n\n\n\n\n\n\nClick on \nUchime on data XX and data XX:non chimeras\n\n\n\n\nThese sequences have been classified to be non-chimeras\n\n\nOnly the \u201cnon-chimeras\u201d output be used for the subsequent steps.\n\n\nAll other sequences, chimeras  and nonclassified will be disregarded.\n\n\n\n\n\n\n\n\nThere are 2 hidden log files also generated from this tool, they contain detailed job information about  the classification into non-chimeras and chimeras.\n\n\n(OPTIONAL) To access the hidden outputs, click on the cog wheel  in the upper right corner of the History panel and select \u201cInclude Hidden Datasets\u201d.\n\n\n\n\n\n\nClick on \nUchime on data XX and data XX:Human-readable output\n\n\n\n\nThe chimeric alignments (with respect to the putative parents) are listed following the \nhuman-readable format\n of the \nUSEARCH-Tool-Suite\n.\n\n\n\n\n\n\n\n\nClick on \nUchime on data XX and data XX:Tabbed output\n\n\n\n\nFor each sequence there are 18 values logged in a tabbed format, as following:\n\n\n\n\n\n\n\n\n\n\nNOTE: The number of sequences that you have may not be exactly the same due to the results of the OTU Clustering step in Section 2.\n\n\nHow many reads per OTU cluster?\n\n\nThe aim here is to generate a full OTU Table which consists of the number of reads found for each group, the representative sequence and the predicted taxonomy.\n\n\n\n\nThis is accomplished by running two tools and merging the resulting outputs together.\n\n\n\n\nThe first tool \u201cMap Reads to OTU\u201d, as the name indicates will map read sequences to the OTU cluster representatives from Section 2.\n\n\n\n\nIn section 2, we clustered the reads into clusters that are 97% similar to all other members of that cluster. Then for each cluster, a representative sequence was selected. However, we do not know the number of reads that are in each cluster. Furthermore, in Section 3 we removed sequences that were potential chimeric sequences; this alters the number of remaining clusters.\n\n\nTherefore, in this step we first find out which of the remaining clusters each read belongs with 97% similarity and this will give us a count of the number of reads per cluster.\n\n\n\n\n\n\n\n\nThe second tool \u201cRDP Multi Classifier\u201d will assign each the OTU representative sequence to a taxonomy level.\n\n\n\n\n\n\nThe last step then merges the information to generate the OTU Table\n\n\n\n\n\n\nMap reads to OTU - how many reads per OTU?\n\n\nIn the tool panel on the left hand side, search for the \nMap Reads to OTU\n tool.\n\n\n\n\nFor \nOTU fasta file\n select dataset \nUchime on data XX and data XX: non_chimeras\n\n\nFor \nInput reads file\n select dataset \nDereplicate on data XX\n\n\nFor \nMinimum identity\n enter 0.97. Like before, this value corresponds to 97% sequence similarity.\n\n\nClick on \nExecute\n\n\n\n\nOutput\n\n\n\n\n\n\nClick on \nMap Reads to OTU on data XX and data XX:rabund\n\n\n\n\nThe output is tab delimited and follows the \nrabund\n format from \nmothur\n.\n\n\nNote that this is just a one-line file which wraps around in the Galaxy display window to look like a multi-line file.\n\n\nIn other words, this is a matrix of one row only, and many columns.\n\n\nThe first column is a label (this is usually the identity)\n\n\nThe second column is the number of OTUs found\n\n\nEach subsequent column is the number of reads found for the corresponding OTUs.\n\n\n\n\n\n\n\n\nClick on \nMap Reads to OTU on data XX and data XX:Pre-OTU Table\n\n\n\n\nThis is the pre OTU table with the following columns: OTU label, Count, Sequence\n\n\n\n\n\n\n\n\nClick on \nMap Reads to OTU on data XX and data XX:relabelled OTU\n\n\n\n\nThis is a FASTA file.\n\n\nThe input reads from \nUchime on data XX and data XX: non_chimeras\n have been re-labelled with convenient labels for parsing, e.g. OTU_1, OTU_2,\nOTU_N, where N is the number of OTUs.\n\n\n\n\n\n\n\n\nThere is one hidden log file also generated from this tool, which reports whether a query sequence matches or not matches the database.\n\n\n(OPTIONAL) To access the hidden output, click on the cog wheel  in the upper right corner of the History panel and select \u201cInclude Hidden Datasets\u201d.\n\n\n\n\n\n\nClick on \nMap Reads to OTU on data XX and data XX:hit list\n\n\n\n\nThis file reports query sequences that match or did not match the database \nCluster OTU on data XX\n following the \nUC-format\n of the \nUSEARCH-Tool-Suite\n.\n\n\nNote that a given read may match two or more OTUs given the identity threshold. In such cases the tool will tend to assign the read to the OTU with highest identity and will break ties arbitrarily.\n\n\nSome reads may not match any OTU for these reasons: (1) the read is chimeric, (2) the read has more than 3% errors, (3) the read has a singleton sequence so was discarded.\n\n\n\n\n\n\n\n\nRDP Classifier - what taxa match the OTUs?\n\n\nA complete OTU table contains the taxonomy assignment of each sequence. To complete the Pre-OTU Table, we will use the \nRDP MultiClassifier\n tool.\n\n\nIn the tool panel on the left hand side, search for the \nRDP MultiClassifier\n tool.\n\n\n\n\nFor \nSelect Gene Trainings Model\n select \u201c16S rRNA\u201d from the dropdown list.\n\n\nFor \nSelect to generate an OTU Table\n click \nYes\n.\n\n\nFor \nRelabelled OTU input reads of the \u2018Map Reads to OTU\u2019 tool in FASTA format\n choose \nMap Reads to OTU on data XX and data XX:relabelled OTU\n\n\nFor \nPRE OTU table of the \u2018Map Reads to OTU\u2019 tool\n select \nMap Reads to OTU on data XX and data XX:Pre-OTU Table\n\n\n\n\nFor \nAssignment confidence cutoff\n, enter 0.8.\n\n\n\n\nThis value is used to specify the assignment confidence cutoff used to determine the assignment count in the hierarchical format. The range is between 0 and 1 with 0.8 being the default value. For sequences that are shorter than 250 base pairs, the tool developers recommend using 0.5 as the confidence threshold. (http://rdp.cme.msu.edu/tutorials/classifier/RDPtutorial_MULTICLASSIFIER.html)\n\n\n\n\n\n\n\n\nFor \nTab delimited output format\n, select \u201cfixrank\u201c from the drop-down list\n\n\n\n\nClick on \nExecute\n\n\n\n\nOutput\n\n\n\n\n\n\nClick on \nRDP MultiClassifier on data XX and data XX:classification_assignment_hierarchical.tab\n\n\n\n\nSequence count for each taxon in the hierarchy\n\n\n\n\n\n\n\n\nClick on \nRDP MultiClassifier on data XX and data XX:classification_assignment_details.tab\n\n\n\n\nSequence-by-sequence classification results including confidence scores at each level of the hierarchy\n\n\n\n\n\n\n\n\nClick on \nRDP MultiClassifier on data XX and data XX:OTU_Table.tab\n\n\n\n\nThe OTU table is composed of the following columns: OTU label, Count, Sequence, Phylogenetic lineage.\n\n\n\n\n\n\n\n\nView taxa with Krona\n\n\nKrona is a tool that shows you a pie chart of the taxa found in your sample.\n\n\nTidy the output\n\n\nCut some columns\n\n\nSearch for \nCut columns\n\n\n\n\nCut columns\n: c2,c4,c7,c10,c13,c16,c19\n\n\nDelimited by\n: Tab\n\n\nFrom\n: the \nRDP MultiClassifier OTU_Table.tab\n\n\nExecute\n\n\n\n\nTake out the quotation marks\n\n\nSearch for \nRegex Find And Replace\n\n\n\n\nFor \nSelect lines from\n: the previous file, \nCut on data XX\n\n\nClick \nInsert Check\n\n\nFind Regex\n: \n\n\nReplacement\n: delete any text in here and leave empty\n\n\nExecute\n\n\n\n\nKrona\n\n\nSearch for \nVisualize with Krona\n\n\n\n\nFor \nSelect input file\n: the previous file, \nRegex Find And Replace on data XX\n\n\nIs this output from MOTHUR\n: \nNo\n\n\nExecute\n\n\n\n\nClick on the eye icon next to the output file.\n\n\n\n\nThis is a pie chart showing the abundance of taxa. The higher taxonomic levels are in the centre, and the lower taxonomic levels are in the outer circle.\n\n\nClick on a taxon to display the information in more detail.\n\n\nMost of our sample is classified as Bacteria.\n\n\nA particularly abundant genus is \nMartelelella\n.\n\n\n\n\n\n\nPhylogeny\n\n\nHow are our taxa related phylogenetically? We will run two tools to investigate.\n\n\n\n\n\nPyNAST\n\n\nThe aim here is to build and visualise the phylogenetic tree.\n\n\n\n\nFirst, we align the sequences to a template sequence using PyNAST.\n\n\nPyNast is a reimplementation of the NAST algorithm to align each provided sequence (the \u201ccandidate\u201d sequence) to the best-matching sequence in a pre-aligned database of sequences (the \u201ctemplate\u201d sequence).\n\n\n\n\nIn the tool panel on the left hand side, search for the \nPyNAST\n tool.\n\n\n\n\nFor \nCandidate file (Fasta format)\n select \nUchime on data XX and data XX:non_chimeras\n\n\nFor \nTemplate alignment file (Fasta format)\n, select \ncore_set_aligned.fasta\n\n\n\n\nFor \nMinimum sequence length\n, enter 1000.\n\n\n\n\nThe minimum sequence length is the length to include in the NAST alignment and it has to be set according to your set of your sequences.\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nOutputs:\n\n\n\n\n\n\nClick on \nPyNAST on data XX and data XX: pynast aligned\n\n\n\n\nThis file contains the alignment. You will find that the number of sequences might have decreased. This means  that the alignment for some sequences failed. More information is given in the log file and the failure file, which are hidden outputs.\n\n\n\n\n\n\n\n\n(OPTIONAL) To access the hidden outputs, click on the cog wheel in the upper right corner of the History  panel and select \u201cInclude Hidden Datasets\u201d.\n\n\n\n\nClick on \nPyNAST on data XX and data XX: pynast log file\n\n\n\n\nThis file is composed of the following columns:\n\n\n\n\ncandidate sequence ID\n\n\ncandidate nucleotide count\n\n\nerrors\n\n\ntemplate ID\n\n\nBLAST percent identify to template\n\n\ncandidate nucleotide count post-NAST\n\n\n\n\nYou will observe that some sequences have an entry in the error column: \u201cNo search results\u201d. These are the sequences that failed to align.\n\n\n\n\n\n\nClick on \nPyNAST on data XX and data XX: pynast failure\n\n\n\n\nThis file contains the sequences that failed to align. We already found out through the log file which sequences failed to align; here those sequences are given in FASTA format.\n\n\n\n\n\n\n\n\nFastTree\n\n\nNext we use \u201cFast Tree\u201d to generate the phylogenetic tree using the aligned sequenced file.\n\n\nIn the tool panel on the left hand side, search for the \nFastTree\n tool.\n\n\n\n\nFor \nAligned sequences file (FASTA format)\n, select \nPyNAST on data XX and data XX:pynast aligned\n\n\nFor \nProtein or nucleotide alignment\n select \u201cNucleotide\u201d\n\n\nClick \nExecute\n\n\n\n\nOutput\n\n\n\n\n\n\nClick on \nFastTree on data 18:tree.nhx\n\n\n\n\nTo visualize the phylogenetic tree, click on the \u201cVisualize\u201d icon \n under the file name.\n\n\nClick on \nPhyloviz\n\n\nPhyloviz is the interactive Phylogenetic Tree Visualizer included from Galaxy.  Currently Phyloviz has only one entry point, which is via the \u201cVisualize - View in Phyloviz\u201d icon that will appear for all supported phylogenetic data sets.  \n\n\nPhyloviz will lay out the tree in a linear format. All phylogenetic distances are normalized to a value between 0 to 1.0 inclusive, and a default value of 250px would represent 1.0 units from a parent node to child node. The laying out of phyloviz is \u201cin-place\u201d meaning that the tree is presented in the same order as it is represented in the data and that no nodes are shuffled.\n\n\nPhyloviz supports a number of user interaction features to help you present, analyze and share the visualization. Please see the Galaxy wiki for more information on Phyloviz.\n\n\n\n\n\n\n\n\n(OPTIONAL) To access the hidden log file, click on the cog wheel  in the upper right corner of the History panel and select \u201cInclude Hidden Datasets\u201d.\n\n\n\n\n\n\nClick on \nFastTree on data XX:log_FastTree_run.txt\n\n\n\n\nThis is the log file from Fast tree and shows job related information. It is not required for the analysis workflow.\n\n\n\n\n\n\n\n\nWas sampling sufficient? Rarefaction analysis\n\n\nThe aim here is to generate an intra-sample rarefaction curve to determine if the sampling effort was sufficient.\n\n\n\n\nRarefaction curves provide a way of comparing the richness observed in different samples although it is a better measure of sample diversity.\n\n\nBriefly, it plots the average number of OTUs that you would expect to observe against the number of sequences.\n\n\nIf the curve plateaus off, then it is a good indication that the sample is saturated and you have captured the majority (if not all) of species/strains present in the sample.\n\n\nHowever, if the curve does not plateau off, this suggests there may still be more species/strains that have not been captured in your data and you need increase the size of your sample.\n\n\n\n\nRarefaction tool\n\n\nIn the tool panel on the left hand side, search for the \nRarefaction\n tool.\n\n\n\n\nFor \nInput file format\n select \nrabund\n from the dropdown list\n\n\nFor \nOTU list (rabund or sabund format)\n, select \nMap Reads to OTU on data XX and data XX:rabund\n\n\n\n\nFor \nMinimum identity used in OTU clustering\n, enter the minimum identity used when you generated the OTU Table. In this tutorial we used 0.97.\n\n\n\n\nIn case you can\u2019t remember the minimum identity used, go back to the output file \nCluster OTU on data XX\n in your History. Click on the file name to extend the dataset information. Click on the \u201cView details\u201d icon. In the Input Parameter section you will find the \u201cMinimum cluster radius\u201d you used in the OTU Clustering step.\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nOutput\n\n\n\n\n\n\nClick on \nRarefaction on data XX\n.\n\n\n\n\nThe output is a tabbed delimited file with the following columns:\n\n\nThe first column (numsampled): the number sampled and indicates the level of sampling intensity (by default this information is provided every 100 individuals)\n\n\nThe second column (0.03) is the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1000 by default. This would represents the data for the y-axis for the corresponding minimum identity (1-0.97=0.03).\n\n\nThe third column (lci) and fourth column (hci) represent the confidence intervals.\n\n\n\n\n\n\n\n\nTo plot the rarefaction curve:\n\n\n\n\nClick on \nRarefaction on data XX\n to extend the dataset information.\n\n\nClick on the \u201cVisualize\u201d icon\n\n\nSelect \u201cScatterplot\u201d\n\n\nUnder Column 1, highlight \nX Column\n (the number sampled)\n\n\nUnder Column 2, highlight \nY Column\n (the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1,000 by default).\n\n\n\n\n\n\n\n\nClick Draw\n\n\n\n\n\n\nEstimate diversity\n\n\nThe aim here is to estimate the diversity and richness of the sample.\n\n\n\n\nCollector\ns curves describe how the richness or diversity change as you add more samples into the dataset.\n\n\nIf a collector\ns curve plateaus, it is a good indication that enough samples were collected and you can have confidence in the last value of the curve.\n\n\n\n\nCollector\ns curve\n\n\nIn the tool panel on the left hand side, search for the \nCollector Curve\n tool.\n\n\n\n\nFor \nOTU list (rabund, sabund, list or shared format)\n, select \nMap Reads to OTU on data XX and data XX:rabund\n\n\n\n\nFor \nLabels - OTU labels\n, Click \nSelect\n and make sure that \n0.03\n appears in the box.\n\n\n\n\nThis correspondd to 97%. Note that this value is the inverse of other similarity thresholds we used thus far (1-0.97=0.03) and is the default value.\n\n\n\n\n\n\n\n\nFor \nCalculators\n, there is no need to change anything from the default calculators:\n\n\n\n\nchao\n - Community richness  - the Chao estimator\n\n\ninvsimpson\n - Community diversity - the Simpson index\n\n\nnpshannon\n - Community diversity - the non-parametric Shannon index.\n\n\n\n\n\n\n\n\nClick \nExecute\n\n\n\n\n\n\nOutput\n\n\n\n\n\n\nClick on \nCollector Curve on data XX:tab\n\n\n\n\nThis file provides a summary containing the following fields: number of sequences, the sample coverage, the number of observed OTUs, and then a summary of each of the selected calculators that were applied to the sample.         \n\n\n\n\n\n\n\n\nClick on \nCollector Curve on data XX:tab (invsimpson)\n\n\n\n\nThe \nSimpson\u2019s Inverse Index\n also referred to as Simpson\u2019s Reciprocal Index is a measure of diversity.\n\n\nSpecies diversity is a way to compare samples that incorporates both a measure of evenness (representation by each species) and richness (number of each species in the sample).\n\n\nThis index starts with the value of 1 as the lowest possible figure. This figure would represent a community containing only one species. The higher the value, the greater the diversity. The maximum value is the number of species in the sample.\n\n\n\n\n\n\n\n\nClick on \nCollector Curve on data XX:tab (npshannon)\n\n\n\n\nThe \nnon-parametric Shannon Index\n, like the Simpson\u2019s Inverse Index, is a diversity estimator and calculates a non-parametric estimate of the classical \nShannon\n diversity Index for an OTU definition.\n\n\nThe interpretation of the curve has to be performed in a comparison to the diversity curve of one or more communities.\n\n\n\n\n\n\n\n\nClick on \nCollector Curve on data XX:tab (chao)\n\n\n\n\n\n\nThe \nChao1 estimator\n is a species richness estimator. The species richness estimators estimate the total number of species present in a community. The Chao1 index estimator the species richness for one community based on the observed species frequencies or presence/absence data.\n\n\n\n\n\n\nIf you compare the rarefaction curve (observed richness) and Chao1 estimator curve (estimated richness), you will observe a gap. The greater estimated richness in comparison to the observed richness usually indicates that with further sampling, the richness would likely continue to increase. Please note that if a sample contains many singletons, it is likely that more undetected OTUs exist, and the Chao1 index will estimate greater species richness than it would for a sample without rare OTUs.\n\n\n\n\n\n\n\n\n\n\nThese three outputs are tabbed delimited with the following columns:\n\n\n\n\n\n\nFirst column (numsampled): is the number sampled and indicates the level of sampling intensity (by default this information is provided every 100 individuals)\n\n\n\n\n\n\nThe second column (0.03) is the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1000 by default. This would represents the data for the y-axis for the corresponding minimum identity (1-0.97=0.03).\n\n\n\n\n\n\nThe third column (lci) and fourth column (hci) represent the confidence intervals\n\n\n\n\n\n\nThese files can be plotted similar to the rarefaction curve in the previous step.\n\n\nPlot the collector\u2019s curves\n\n\n\n\nClick on \nCollector Curve on data XX:tab (invsimpson)\n to extend the dataset information.\n\n\nClick on the now accessible \u201cVisualize\u201d icon\n\n\n\n\nSelect \u201cScatterplot\u201d\n\n\n\n\n\n\nUnder Column 1, highlight \nX Column\n (the number sampled)\n\n\n\n\nUnder Column 2, highlight \nY Column\n (the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1,000 by default).\n\n\nClick \nDraw\n\n\n\n\nRepeat to plot the curves from the other calculators.\n\n\nThe workflow canvas\n\n\n\n\nReferences\n\n\n\n\n\n\nWoese CR, Kandler O, Wheelis ML (1990) Towards a natural system of organisms: proposal for the domains Archaea, Bacteria, and Eucarya. Proc Natl Acad Sci U S A 87: 4576-4579.\n\n\n\n\n\n\nLane DJ, Pace B, Olsen GJ, Stahl DA, Sogin ML, et al. (1985) Rapid determination of 16S ribosomal RNA sequences for phylogenetic analyses. Proc Natl Acad Sci U S A 82: 6955-6959.\n\n\n\n\n\n\nKunin V, Copeland A, Lapidus A, Mavromatis K, Hugenholtz P (2008) A bioinformatician\ns guide to metagenomics. Microbiol Mol Biol Rev 72: 557-578.\n\n\n\n\n\n\nHandelsman J, Rondon MR, Brady SF, Clardy J, Goodman RM (1998) Molecular biological access to the chemistry of unknown soil microbes: a new frontier for natural products. Chem Biol 5: R245-249.\n\n\n\n\n\n\nTurnbaugh PJ, Ley RE, Hamady M, Fraser-Liggett CM, Knight R, et al. (2007) The human microbiome project. Nature 449: 804-810.\n\n\n\n\n\n\nHolmes S, Alekseyenko A, Timme A, Nelson T, Pasricha PJ, et al. (2011) Visualization and statistical comparisons of microbial communities using R packages on phylochip data. Pac Symp Biocomput: 142-153.\n\n\n\n\n\n\nHamady M, Lozupone C, Knight R (2010) Fast UniFrac: facilitating high-throughput phylogenetic analyses of microbial communities including analysis of pyrosequencing and PhyloChip data. ISME J 4: 17-27.\n\n\n\n\n\n\nBrodie EL, Desantis TZ, Joyner DC, Baek SM, Larsen JT, et al. (2006) Application of a high-density oligonucleotide microarray approach to study bacterial population dynamics during uranium reduction and reoxidation. Appl Environ Microbiol 72: 6288-6298.", 
            "title": "Metagenomics"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#metagenomics", 
            "text": "In development  Based on material by QFAB  http.qfab.org", 
            "title": "Metagenomics"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#tutorial-overview", 
            "text": "In this tutorial we cover the concepts of metagenomics analysis in 16S rRNA.  What\u2019s not covered:  This introductory tutorial covers the steps required for the first part of a 16S rRNA metagenomics study applied to samples from a single site. As such we only show analyses that can be applied to a single environment, that is, identifying what organisms are in your sample (diversity), and how many organisms there are in the sample (richness). Similar same steps would be applied if you had samples from multiple sites, with additional analyses that can compare the diversity and richness between samples. The latter part is not covered by this tutorial.", 
            "title": "Tutorial Overview"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#background", 
            "text": "", 
            "title": "Background"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#16s-rrna-sequencing", 
            "text": "The application of culture-independent rRNA-based phylogenetics to the study of bacterial diversity was first explored by researchers in the 1980s e.g. [2] and was used by Carl Woese to delineate the main branches of life [1]. These rRNA based analyses remain central methods in microbiology both for the exploration of species diversity but also or the application in bacterial identification.  The development of pyrosequencing technologies and the emergence of next generation DNA sequencing have changed the scales at which scientists can systematically survey the 16S rRNA content of biological samples and has been a key driver behind initiatives such as the human microbiome project [5].  In the broadest sense, 16S rRNA sequencing should not be confused with metagenomics which has been defined as  the application of shotgun sequencing to DNA obtained directly from an environmental sample or series of related samples, producing at least 50Mbp of randomly sampled sequence data  [3] This is also in contrast to functional metagenomics whereby environmental DNA is first cloned and subsequently screened for specific functional activities e.g. [4]. Kunin et al elegantly argue that 16S rRNA profiling should in fact exist as a mandatory  Premetagenome community composition profiling  step in more comprehensive surveys [3]. There is discussion and debate as to how deep this sequencing could be performed but at JGI at least, a single 384 well plate is routinely surveyed.  Irrespective of the nuances of terminology, metagenomics is a baseline technology for understanding the ecology and evolution of microbial ecosystems upon which hypotheses and experimental strategies are built.", 
            "title": "16S rRNA sequencing"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#experimental-design-is-key", 
            "text": "Most 16S strategies are biased towards the measurement of bacterial and archaeal constituents of the environment and eukaryotes (e.g. fungi and protists) are excluded. This compromises the ability to measure the whole ecological spectrum of a microbial community; the larger and non-coding and thus uninterpretable parts of the eukaryotic genome are problematic. This is largely driving strategies that encompass additional metatranscriptomics surveys. The studies are thus oriented towards the sequence-tractable bacterial, archaeal and viral components of the research community.", 
            "title": "Experimental design is key"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#limitations-of-the-16s-rrna-profiling-strategy", 
            "text": "The 16S rRNA gene copy number of variable between bacterial species and this is further confounded by PCR amplification biases which skew estimates of the community composition.", 
            "title": "Limitations of the 16S rRNA profiling strategy"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#goals", 
            "text": "The goal of the 16S study is to understand the complexity of the community being sampled. This is assessed as a function of the number of species in the community (richness) and their relative abundances (evenness).", 
            "title": "Goals"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#the-workflow-in-galaxy", 
            "text": "The process presented in this workshop is aimed to be an introduction for molecular biologists to 16S rRNA metagenomics analysis. The workflow is also implemented such that it can be run using a standard desktop or laptop environment without the requirements of a large cluster or cloud infrastructure.  The steps are:  Dereplicate reads\nCluster reads into Operational Taxonomic Units (OTU)\nChimera detection and removal\nOTU Table\nPhylogenetic Tree alignment\nRarefaction analysis\nCollector Curve analysis  Figure 1:   We will also perform an extra step where we visualize the taxa present in the sample, using the tool Krona.", 
            "title": "The workflow in Galaxy"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#where-is-the-data-in-this-tutorial-from", 
            "text": "We use the same data from the  Mothur Marine community analysis , that is  the study from the  Global Ocean Sampling (GOS) Expedition . However we only concentrate on one site as opposed to the 14 sites they sampled.", 
            "title": "Where is the data in this tutorial from?"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#preparation", 
            "text": "Open a browser and go to your Galaxy server, for example, Galaxy Australia: usegalaxy.org.au", 
            "title": "Preparation"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#import-the-data", 
            "text": "In Galaxy, go to  Shared Data  and then  Data Libraries .   Search for  Metagenomics 16S rRNA Data  and click on it.  Tick the box next to the three files and then click the  To History  button, and select  as Datasets .  Name a new history and click  Import  These three files should now be in your current history.   Click on the eye icon on the top right of each fasta file to view the first part of the file.", 
            "title": "Import the data"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#alternative-way-to-import-data", 
            "text": "Download the data directly to your computer using these URLs, then upload to Galaxy:  https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Metagenomics_BASIC/seqs.fasta\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Metagenomics_BASIC/gold.fasta\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Metagenomics_BASIC/core_set_aligned.fasta   Once files are downloaded, in Galaxy click on  Get data Upload File  Click  Choose local file , locate the local copy of each of the three fasta files and upload.  You can leave File Format as Auto-detect, or if you prefer, set it to fasta.  Click  Start  and wait for the files to upload to Galaxy. It can take a couple of minutes.", 
            "title": "Alternative way to import data"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#keep-only-the-unique-reads", 
            "text": "The aim here is to reduce the number of reads in the input file into clusters of identical sequences.", 
            "title": "Keep only the unique reads"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#dereplicate", 
            "text": "In the tool panel (left hand side) search for the  Dereplicate  tool and click on it.   For  Input sequence file  select the  seqs.fasta  dataset  For  Criteria used for duplicate detection  select  Full length   There are two possible modes in the dereplication tool:\n(1)  full-length  where the full length of the two sequences must be identical before being grouped together or\n(2)  prefix  where the first section of the two sequences are identical   Click on  Execute", 
            "title": "Dereplicate"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output", 
            "text": "Click on the name of the job  Dereplicate on data XX  in the History panel (right hand side) and you will see the number of sequences have been reduced from 1,472 in the input data  seqs.fasta  to 1,459 sequences.  Examine the output by clicking on the eye icon  in the top right hand corner of this step.    NOTE: The size=XXXX annotation in the id line of the fasta file indicates the number of reads that were exactly the same as this representative sequence.    (OPTIONAL) You can rename the output by clicking on the pencil icon  on the top right hand corner of the output. Click on the \u201cAttributes tab\u201d and then  type in a new name in the \u201cName\u201d field and click on Save.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#cluster-sequences-into-groups", 
            "text": "The aim here is to cluster the output from Step 1 into groups of sequences that are 97% similar to each other.   Similar sequences are assumed to belong to the same taxonomic groups. * These groups are known as Operational Taxonomic Units (OTUs) and the number of clusters that result are indicative of the number of species that are present in this sample.", 
            "title": "Cluster sequences into groups"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#cluter-otus", 
            "text": "In the tool panel on the left hand side, search for the  Cluster OTU  tool.   For  Input sequence file , select the output from Step 1:   Dereplicate on data XX  For  Minimum cluster radius , enter 0.97. This value corresponds to 97% sequence identity.  Click on  Execute", 
            "title": "Cluter OTUs"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output_1", 
            "text": "Click on the name of the job  Cluster OTU on data 4  in the History panel (right hand side) and you will find that the number of sequences has decreased to 559 sequences.   Examine the output by clicking on the eye icon  in the top right hand corner of this step.  The output file is in Fasta format where each sequence is the representative of an OTU.  Figure 2 below, provides a summary of the clustering approach. Reads are represented by solid dots. Those that are 97% similar to each other are grouped together into an OTU as represented by the blue dashed circles.  In this example, there are 3 OTUs. The reads that represents the centroid of each cluster are shown as red dots and these red dots form the representative of the corresponding OTU. These are the sequences that are reported in the output file. In this tutorial, the output file has 559 sequences, meaning that 559 OTUs were identified.  NOTE: The number of sequences that you have may not be exactly the same as mentioned here. This is so as the clustering process starts by randomly selecting a read as the center of a cluster (see figure below). Since this is a random selection, each time you perform a clustering process, a different read can be selected and thus affect the end result.   For more detailed description of the OTU clustering algorithm, click  here .  Figure 2.   Please Note: The \u201csize=XX\u201d annotation in the identifier line is NOT the number of sequences that is in the corresponding cluster (OTU). This value is the same as the input file.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#remove-chimeras", 
            "text": "The aim here is to: identify and filter chimeric sequences utilizing a reference dataset containing nucleotide sequences believed to be free of chimeras.", 
            "title": "Remove chimeras"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#uchime", 
            "text": "In the tool panel on the left hand side, search for the  Uchime  tool.   For  Mode to detect chimeras , select \u201cref\u201d (reference mode).   There are two possible modes in the Uchime tool for chimera detection: (1)  ref  where a reference dataset of parent sequences believed to be chimera-free is provided by the user or (2)  de-novo  where a database is constructed from the query sequences by using the abundance data.   For the second field  Input reference file  select the  Cluster OTU on data XX  For the third  field  Reference Database , select the  gold.fasta . This file (downloaded from http://drive5.com/uchime/gold.fa) contains nucleotide sequences believed to be free of chimeras.  Click on  Execute", 
            "title": "Uchime"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output_2", 
            "text": "Click on  Uchime on data XX and data XX:chimeras   These sequences have been classified to be chimeras     Click on  Uchime on data XX and data XX:non chimeras   These sequences have been classified to be non-chimeras  Only the \u201cnon-chimeras\u201d output be used for the subsequent steps.  All other sequences, chimeras  and nonclassified will be disregarded.     There are 2 hidden log files also generated from this tool, they contain detailed job information about  the classification into non-chimeras and chimeras.  (OPTIONAL) To access the hidden outputs, click on the cog wheel  in the upper right corner of the History panel and select \u201cInclude Hidden Datasets\u201d.    Click on  Uchime on data XX and data XX:Human-readable output   The chimeric alignments (with respect to the putative parents) are listed following the  human-readable format  of the  USEARCH-Tool-Suite .     Click on  Uchime on data XX and data XX:Tabbed output   For each sequence there are 18 values logged in a tabbed format, as following:      NOTE: The number of sequences that you have may not be exactly the same due to the results of the OTU Clustering step in Section 2.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#how-many-reads-per-otu-cluster", 
            "text": "The aim here is to generate a full OTU Table which consists of the number of reads found for each group, the representative sequence and the predicted taxonomy.   This is accomplished by running two tools and merging the resulting outputs together.   The first tool \u201cMap Reads to OTU\u201d, as the name indicates will map read sequences to the OTU cluster representatives from Section 2.   In section 2, we clustered the reads into clusters that are 97% similar to all other members of that cluster. Then for each cluster, a representative sequence was selected. However, we do not know the number of reads that are in each cluster. Furthermore, in Section 3 we removed sequences that were potential chimeric sequences; this alters the number of remaining clusters.  Therefore, in this step we first find out which of the remaining clusters each read belongs with 97% similarity and this will give us a count of the number of reads per cluster.     The second tool \u201cRDP Multi Classifier\u201d will assign each the OTU representative sequence to a taxonomy level.    The last step then merges the information to generate the OTU Table", 
            "title": "How many reads per OTU cluster?"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#map-reads-to-otu-how-many-reads-per-otu", 
            "text": "In the tool panel on the left hand side, search for the  Map Reads to OTU  tool.   For  OTU fasta file  select dataset  Uchime on data XX and data XX: non_chimeras  For  Input reads file  select dataset  Dereplicate on data XX  For  Minimum identity  enter 0.97. Like before, this value corresponds to 97% sequence similarity.  Click on  Execute", 
            "title": "Map reads to OTU - how many reads per OTU?"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output_3", 
            "text": "Click on  Map Reads to OTU on data XX and data XX:rabund   The output is tab delimited and follows the  rabund  format from  mothur .  Note that this is just a one-line file which wraps around in the Galaxy display window to look like a multi-line file.  In other words, this is a matrix of one row only, and many columns.  The first column is a label (this is usually the identity)  The second column is the number of OTUs found  Each subsequent column is the number of reads found for the corresponding OTUs.     Click on  Map Reads to OTU on data XX and data XX:Pre-OTU Table   This is the pre OTU table with the following columns: OTU label, Count, Sequence     Click on  Map Reads to OTU on data XX and data XX:relabelled OTU   This is a FASTA file.  The input reads from  Uchime on data XX and data XX: non_chimeras  have been re-labelled with convenient labels for parsing, e.g. OTU_1, OTU_2, OTU_N, where N is the number of OTUs.     There is one hidden log file also generated from this tool, which reports whether a query sequence matches or not matches the database.  (OPTIONAL) To access the hidden output, click on the cog wheel  in the upper right corner of the History panel and select \u201cInclude Hidden Datasets\u201d.    Click on  Map Reads to OTU on data XX and data XX:hit list   This file reports query sequences that match or did not match the database  Cluster OTU on data XX  following the  UC-format  of the  USEARCH-Tool-Suite .  Note that a given read may match two or more OTUs given the identity threshold. In such cases the tool will tend to assign the read to the OTU with highest identity and will break ties arbitrarily.  Some reads may not match any OTU for these reasons: (1) the read is chimeric, (2) the read has more than 3% errors, (3) the read has a singleton sequence so was discarded.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#rdp-classifier-what-taxa-match-the-otus", 
            "text": "A complete OTU table contains the taxonomy assignment of each sequence. To complete the Pre-OTU Table, we will use the  RDP MultiClassifier  tool.  In the tool panel on the left hand side, search for the  RDP MultiClassifier  tool.   For  Select Gene Trainings Model  select \u201c16S rRNA\u201d from the dropdown list.  For  Select to generate an OTU Table  click  Yes .  For  Relabelled OTU input reads of the \u2018Map Reads to OTU\u2019 tool in FASTA format  choose  Map Reads to OTU on data XX and data XX:relabelled OTU  For  PRE OTU table of the \u2018Map Reads to OTU\u2019 tool  select  Map Reads to OTU on data XX and data XX:Pre-OTU Table   For  Assignment confidence cutoff , enter 0.8.   This value is used to specify the assignment confidence cutoff used to determine the assignment count in the hierarchical format. The range is between 0 and 1 with 0.8 being the default value. For sequences that are shorter than 250 base pairs, the tool developers recommend using 0.5 as the confidence threshold. (http://rdp.cme.msu.edu/tutorials/classifier/RDPtutorial_MULTICLASSIFIER.html)     For  Tab delimited output format , select \u201cfixrank\u201c from the drop-down list   Click on  Execute", 
            "title": "RDP Classifier - what taxa match the OTUs?"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output_4", 
            "text": "Click on  RDP MultiClassifier on data XX and data XX:classification_assignment_hierarchical.tab   Sequence count for each taxon in the hierarchy     Click on  RDP MultiClassifier on data XX and data XX:classification_assignment_details.tab   Sequence-by-sequence classification results including confidence scores at each level of the hierarchy     Click on  RDP MultiClassifier on data XX and data XX:OTU_Table.tab   The OTU table is composed of the following columns: OTU label, Count, Sequence, Phylogenetic lineage.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#view-taxa-with-krona", 
            "text": "Krona is a tool that shows you a pie chart of the taxa found in your sample.", 
            "title": "View taxa with Krona"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#tidy-the-output", 
            "text": "Cut some columns  Search for  Cut columns   Cut columns : c2,c4,c7,c10,c13,c16,c19  Delimited by : Tab  From : the  RDP MultiClassifier OTU_Table.tab  Execute   Take out the quotation marks  Search for  Regex Find And Replace   For  Select lines from : the previous file,  Cut on data XX  Click  Insert Check  Find Regex :   Replacement : delete any text in here and leave empty  Execute", 
            "title": "Tidy the output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#krona", 
            "text": "Search for  Visualize with Krona   For  Select input file : the previous file,  Regex Find And Replace on data XX  Is this output from MOTHUR :  No  Execute   Click on the eye icon next to the output file.   This is a pie chart showing the abundance of taxa. The higher taxonomic levels are in the centre, and the lower taxonomic levels are in the outer circle.  Click on a taxon to display the information in more detail.  Most of our sample is classified as Bacteria.  A particularly abundant genus is  Martelelella .", 
            "title": "Krona"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#phylogeny", 
            "text": "How are our taxa related phylogenetically? We will run two tools to investigate.", 
            "title": "Phylogeny"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#pynast", 
            "text": "The aim here is to build and visualise the phylogenetic tree.   First, we align the sequences to a template sequence using PyNAST.  PyNast is a reimplementation of the NAST algorithm to align each provided sequence (the \u201ccandidate\u201d sequence) to the best-matching sequence in a pre-aligned database of sequences (the \u201ctemplate\u201d sequence).   In the tool panel on the left hand side, search for the  PyNAST  tool.   For  Candidate file (Fasta format)  select  Uchime on data XX and data XX:non_chimeras  For  Template alignment file (Fasta format) , select  core_set_aligned.fasta   For  Minimum sequence length , enter 1000.   The minimum sequence length is the length to include in the NAST alignment and it has to be set according to your set of your sequences.     Click  Execute    Outputs:    Click on  PyNAST on data XX and data XX: pynast aligned   This file contains the alignment. You will find that the number of sequences might have decreased. This means  that the alignment for some sequences failed. More information is given in the log file and the failure file, which are hidden outputs.     (OPTIONAL) To access the hidden outputs, click on the cog wheel in the upper right corner of the History  panel and select \u201cInclude Hidden Datasets\u201d.   Click on  PyNAST on data XX and data XX: pynast log file   This file is composed of the following columns:   candidate sequence ID  candidate nucleotide count  errors  template ID  BLAST percent identify to template  candidate nucleotide count post-NAST   You will observe that some sequences have an entry in the error column: \u201cNo search results\u201d. These are the sequences that failed to align.    Click on  PyNAST on data XX and data XX: pynast failure   This file contains the sequences that failed to align. We already found out through the log file which sequences failed to align; here those sequences are given in FASTA format.", 
            "title": "PyNAST"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#fasttree", 
            "text": "Next we use \u201cFast Tree\u201d to generate the phylogenetic tree using the aligned sequenced file.  In the tool panel on the left hand side, search for the  FastTree  tool.   For  Aligned sequences file (FASTA format) , select  PyNAST on data XX and data XX:pynast aligned  For  Protein or nucleotide alignment  select \u201cNucleotide\u201d  Click  Execute   Output    Click on  FastTree on data 18:tree.nhx   To visualize the phylogenetic tree, click on the \u201cVisualize\u201d icon   under the file name.  Click on  Phyloviz  Phyloviz is the interactive Phylogenetic Tree Visualizer included from Galaxy.  Currently Phyloviz has only one entry point, which is via the \u201cVisualize - View in Phyloviz\u201d icon that will appear for all supported phylogenetic data sets.    Phyloviz will lay out the tree in a linear format. All phylogenetic distances are normalized to a value between 0 to 1.0 inclusive, and a default value of 250px would represent 1.0 units from a parent node to child node. The laying out of phyloviz is \u201cin-place\u201d meaning that the tree is presented in the same order as it is represented in the data and that no nodes are shuffled.  Phyloviz supports a number of user interaction features to help you present, analyze and share the visualization. Please see the Galaxy wiki for more information on Phyloviz.     (OPTIONAL) To access the hidden log file, click on the cog wheel  in the upper right corner of the History panel and select \u201cInclude Hidden Datasets\u201d.    Click on  FastTree on data XX:log_FastTree_run.txt   This is the log file from Fast tree and shows job related information. It is not required for the analysis workflow.", 
            "title": "FastTree"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#was-sampling-sufficient-rarefaction-analysis", 
            "text": "The aim here is to generate an intra-sample rarefaction curve to determine if the sampling effort was sufficient.   Rarefaction curves provide a way of comparing the richness observed in different samples although it is a better measure of sample diversity.  Briefly, it plots the average number of OTUs that you would expect to observe against the number of sequences.  If the curve plateaus off, then it is a good indication that the sample is saturated and you have captured the majority (if not all) of species/strains present in the sample.  However, if the curve does not plateau off, this suggests there may still be more species/strains that have not been captured in your data and you need increase the size of your sample.", 
            "title": "Was sampling sufficient? Rarefaction analysis"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#rarefaction-tool", 
            "text": "In the tool panel on the left hand side, search for the  Rarefaction  tool.   For  Input file format  select  rabund  from the dropdown list  For  OTU list (rabund or sabund format) , select  Map Reads to OTU on data XX and data XX:rabund   For  Minimum identity used in OTU clustering , enter the minimum identity used when you generated the OTU Table. In this tutorial we used 0.97.   In case you can\u2019t remember the minimum identity used, go back to the output file  Cluster OTU on data XX  in your History. Click on the file name to extend the dataset information. Click on the \u201cView details\u201d icon. In the Input Parameter section you will find the \u201cMinimum cluster radius\u201d you used in the OTU Clustering step.     Click  Execute", 
            "title": "Rarefaction tool"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output_5", 
            "text": "Click on  Rarefaction on data XX .   The output is a tabbed delimited file with the following columns:  The first column (numsampled): the number sampled and indicates the level of sampling intensity (by default this information is provided every 100 individuals)  The second column (0.03) is the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1000 by default. This would represents the data for the y-axis for the corresponding minimum identity (1-0.97=0.03).  The third column (lci) and fourth column (hci) represent the confidence intervals.     To plot the rarefaction curve:   Click on  Rarefaction on data XX  to extend the dataset information.  Click on the \u201cVisualize\u201d icon  Select \u201cScatterplot\u201d  Under Column 1, highlight  X Column  (the number sampled)  Under Column 2, highlight  Y Column  (the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1,000 by default).     Click Draw", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#estimate-diversity", 
            "text": "The aim here is to estimate the diversity and richness of the sample.   Collector s curves describe how the richness or diversity change as you add more samples into the dataset.  If a collector s curve plateaus, it is a good indication that enough samples were collected and you can have confidence in the last value of the curve.", 
            "title": "Estimate diversity"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#collectors-curve", 
            "text": "In the tool panel on the left hand side, search for the  Collector Curve  tool.   For  OTU list (rabund, sabund, list or shared format) , select  Map Reads to OTU on data XX and data XX:rabund   For  Labels - OTU labels , Click  Select  and make sure that  0.03  appears in the box.   This correspondd to 97%. Note that this value is the inverse of other similarity thresholds we used thus far (1-0.97=0.03) and is the default value.     For  Calculators , there is no need to change anything from the default calculators:   chao  - Community richness  - the Chao estimator  invsimpson  - Community diversity - the Simpson index  npshannon  - Community diversity - the non-parametric Shannon index.     Click  Execute", 
            "title": "Collector's curve"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#output_6", 
            "text": "Click on  Collector Curve on data XX:tab   This file provides a summary containing the following fields: number of sequences, the sample coverage, the number of observed OTUs, and then a summary of each of the selected calculators that were applied to the sample.              Click on  Collector Curve on data XX:tab (invsimpson)   The  Simpson\u2019s Inverse Index  also referred to as Simpson\u2019s Reciprocal Index is a measure of diversity.  Species diversity is a way to compare samples that incorporates both a measure of evenness (representation by each species) and richness (number of each species in the sample).  This index starts with the value of 1 as the lowest possible figure. This figure would represent a community containing only one species. The higher the value, the greater the diversity. The maximum value is the number of species in the sample.     Click on  Collector Curve on data XX:tab (npshannon)   The  non-parametric Shannon Index , like the Simpson\u2019s Inverse Index, is a diversity estimator and calculates a non-parametric estimate of the classical  Shannon  diversity Index for an OTU definition.  The interpretation of the curve has to be performed in a comparison to the diversity curve of one or more communities.     Click on  Collector Curve on data XX:tab (chao)    The  Chao1 estimator  is a species richness estimator. The species richness estimators estimate the total number of species present in a community. The Chao1 index estimator the species richness for one community based on the observed species frequencies or presence/absence data.    If you compare the rarefaction curve (observed richness) and Chao1 estimator curve (estimated richness), you will observe a gap. The greater estimated richness in comparison to the observed richness usually indicates that with further sampling, the richness would likely continue to increase. Please note that if a sample contains many singletons, it is likely that more undetected OTUs exist, and the Chao1 index will estimate greater species richness than it would for a sample without rare OTUs.      These three outputs are tabbed delimited with the following columns:    First column (numsampled): is the number sampled and indicates the level of sampling intensity (by default this information is provided every 100 individuals)    The second column (0.03) is the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1000 by default. This would represents the data for the y-axis for the corresponding minimum identity (1-0.97=0.03).    The third column (lci) and fourth column (hci) represent the confidence intervals    These files can be plotted similar to the rarefaction curve in the previous step.", 
            "title": "Output"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#plot-the-collectors-curves", 
            "text": "Click on  Collector Curve on data XX:tab (invsimpson)  to extend the dataset information.  Click on the now accessible \u201cVisualize\u201d icon   Select \u201cScatterplot\u201d    Under Column 1, highlight  X Column  (the number sampled)   Under Column 2, highlight  Y Column  (the average number of OTUs that were observed for that sampling intensity based on the number of iterations, which is 1,000 by default).  Click  Draw   Repeat to plot the curves from the other calculators.", 
            "title": "Plot the collector\u2019s curves"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#the-workflow-canvas", 
            "text": "", 
            "title": "The workflow canvas"
        }, 
        {
            "location": "/modules/metagenomics/metagenomics/#references", 
            "text": "Woese CR, Kandler O, Wheelis ML (1990) Towards a natural system of organisms: proposal for the domains Archaea, Bacteria, and Eucarya. Proc Natl Acad Sci U S A 87: 4576-4579.    Lane DJ, Pace B, Olsen GJ, Stahl DA, Sogin ML, et al. (1985) Rapid determination of 16S ribosomal RNA sequences for phylogenetic analyses. Proc Natl Acad Sci U S A 82: 6955-6959.    Kunin V, Copeland A, Lapidus A, Mavromatis K, Hugenholtz P (2008) A bioinformatician s guide to metagenomics. Microbiol Mol Biol Rev 72: 557-578.    Handelsman J, Rondon MR, Brady SF, Clardy J, Goodman RM (1998) Molecular biological access to the chemistry of unknown soil microbes: a new frontier for natural products. Chem Biol 5: R245-249.    Turnbaugh PJ, Ley RE, Hamady M, Fraser-Liggett CM, Knight R, et al. (2007) The human microbiome project. Nature 449: 804-810.    Holmes S, Alekseyenko A, Timme A, Nelson T, Pasricha PJ, et al. (2011) Visualization and statistical comparisons of microbial communities using R packages on phylochip data. Pac Symp Biocomput: 142-153.    Hamady M, Lozupone C, Knight R (2010) Fast UniFrac: facilitating high-throughput phylogenetic analyses of microbial communities including analysis of pyrosequencing and PhyloChip data. ISME J 4: 17-27.    Brodie EL, Desantis TZ, Joyner DC, Baek SM, Larsen JT, et al. (2006) Application of a high-density oligonucleotide microarray approach to study bacterial population dynamics during uranium reduction and reoxidation. Appl Environ Microbiol 72: 6288-6298.", 
            "title": "References"
        }, 
        {
            "location": "/modules/workflows/", 
            "text": "Galaxy workflows\n\n\nA workflow is a chain of analysis steps. In Galaxy, we can create a workflow from an existing analysis history, or we can create one visually by adding tools to a canvas.\n\n\nThis tutorial covers building a workflow to analyse a bacterial genome, from input FASTQ sequencing reads to assembly, annotation, and visualization.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nStart\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\nImport a history of data files:\n\n\n\n\nClick on the \nHistory\n cog \n\n\nSelect \nImport from File\n\n\nIn the box called \nArchived History URL\n, paste in this link address to the Galaxy history of input files:\n\n\n\n\nhttps://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz\n\n\n\n\nClick \nImport History\n\n\nWait a few seconds.\n\n\nClick on the \nView all histories\n button \n\n\nSee if the Galaxy history has been imported: it will be called \nimported from archive: Data\n\n\nAbove that pane, click on the \nSwitch to\n button.\n\n\nThen click \nAnalyze Data\n (in the top menu bar).\n\n\n\n\nYou should now have a list of five files in your current history.\n\n\n\n\n\n\nRe-name this history \nWorkflows\n.\n\n\n\n\n\n\nBuild a workflow\n\n\nWe will first write a workflow for genome assembly.\n\n\n\n\nIn the top menu bar in Galaxy, click on \nWorkflow\n.\n\n\n\n\n\n\n\n\nClick on the plus button.\n\n\n\n\n\n\n\n\n\n\nUnder \nWorkflow Name:\n put in \nReads to Annotation\n.\n\n\n\n\n\n\nClick \nSave\n\n\n\n\n\n\nThis will bring up the \nWorkflow Canvas\n, a grid where you can arrange the workflow.\n\n\n\n\n\n\nAdd inputs\n\n\n\n\n\n\nIn the Tools panel, click \nInputs: Input datset\n twice (at the very top of the list).\n\n\n\n\n\n\nA box will appear: drag it to the left and there will be another box underneath it. Drag this also to the left. Your workflow canvas should look like this:\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the first box. Look in the right hand panel (now called \nDetails\n). Under \nLabel\n type in \nR1.fastq\n. Press Enter for the change to be saved.\n\n\n\n\n\n\nRepeat for the second input dataset box, naming that one \nR2.fastq\n.\n\n\n\n\n\n\nAdd the tool \nspades\n\n\n\n\nIn the tools panel, search for \nspades\n and click on the tool name.\nThis puts the spades box onto the workflow canvas.\n\n\n\n\n\n\n\n\n\n\nClick on the spades box and look in the Details pane on the right. This shows all the options in spades. Choose:\n\n\n\n\n\n\nRun only Assembly\n: \nYes\n [the \nYes\n button should be darker grey]\n\n\n\n\nKmers to use separated by commas:\n \n33,55,91\n  [note: no spaces]  \n\n\nCoverage cutoff:\n \nauto\n  \n\n\n\n\nJoin inputs to the tool\n\n\nNow tell spades which input files to use.\n\n\n\n\n\n\nLook at the input dataset box called \nR1.fastq\n and find the small arrow: \n\n\n\n\n\n\nClick on this and drag the arrow over to the spades box input arrow \n next to \nLibraries 1 \n Files 1 \n Forward reads\n.\n\n\n\n\n\n\n\n\n\n\nRepeat for the dataset box \nR2.fastq\n, joining to the spades box next to \nLibraries 1 \n Files 1 \n Reverse reads\n.\n\n\n\n\nSave it and run\n\n\n\n\nClick on the cog at the top right of the workflow canvas and \nSave\n.\n\n\nClick the cog again and choose \nRun\n.\n\n\n\n\nThis brings up a window where you specify the input datasets to use in the workflow.\n\n\n\n\nUnder \nStep1: Input dataset\n choose \nmutant_R1.fastq\n.\n\n\nUnder \nStep2: Input dataset\n choose \nmutant_R2.fastq\n.\n\n\n\n\n\n\n\n\nClick \nRun workflow\n.\n\n\n\n\n\n\nThis will run the workflow (spades) and save the output to the top of your current history in the right hand panel.\n\n\n\n\nView some of the output files with the eye icon to check that the workflow (in this case, just spades) ran correctly.\n\n\n\n\nAdd to the worfklow\n\n\nWe will add another tool to the workflow.\n\n\n\n\n\n\nGo to the top Galaxy panel and click \nWorkflow\n.\n\n\n\n\n\n\nYour workflow \nReads to Annotation\n should be in the list. Click on the drop-down arrow next to this workflow and choose \nEdit\n.\n\n\n\n\n\n\nThis will bring up the Workflow Canvas where we can add more inputs and tools.\n\n\n\n\n\n\nIn the Tools panel search for \nProkka\n and click on the tool name. This will add a Prokka box to the workflow canvas.\n\n\n\n\n\n\nWe need to tell Prokka which genome assembly) to annotate. Join the spades output called \nout_contigs(fasta)\n to the Prokka input called \nContigs to annotate\n.\n\n\n\n\n\n\nClick on the Prokka box and change some of the settings in the right hand Details panel:\n\n\n\n\nSet the following parameters (leave everything else unchanged):\n\n\nLocus tag prefix (\nlocustag)\n: P\n\n\nForce GenBank/ENA/DDJB compliance (\ncompliant)\n: \nNo\n\n\nSequencing Centre ID (\ncentre)\n: V\n\n\nUse genus-specific BLAST database\n \nNo\n  \n\n\n\n\n\n\n\n\nClick on the cog to the top right of the workflow canvas to save.\n\n\n\n\n\n\nClick on the cog again to run.\n\n\n\n\nAgain, choose the input files: \nmutant_R1.fastq\n and \nmutant_R2.fastq\n, and then click \nRun workflow\n.\n\n\n\n\n\n\n\n\nThe output from the workflow (files from spades and prokka) will appear at the top of the History panel.\n\n\n\n\n\n\nClick on the eye icon for some files to verify the workflow ran correctly.      \n\n\n\n\n\n\nAdd more to the workflow\n\n\nWe will add a visualization tool to view the genome annotation.\n\n\n\n\n\n\nGo to the top Galaxy panel and click \nWorkflow\n.\n\n\n\n\n\n\nYour workflow \nReads to Annotation\n should be in the list. Click on the drop-down arrow next to this workflow and choose \nEdit\n.\n\n\n\n\n\n\nThis will bring up the Workflow Canvas where we can add more inputs and tools.\n\n\n\n\n\n\nIn the Tools panel, search for \nJBrowse\n and click on \nJBrowse genome browser\n. This will add a JBrowse box to the workflow canvas.\n\n\n\n\n\n\nClick on the JBrowse box. In the Details pane:\n\n\n\n\nUnder \nReference genome to display\n choose \nUse a genome from history\n.\n\n\n\n\nFor \nProduce a Standalone Instance\n select \nYes\n.\n\n\n\n\n\n\nFor \nGenetic Code\n choose \n11: The Bacterial, Archaeal and Plant Plastid Code\n.\n\n\n\n\n\n\nUnder \nJBrowse-in-Galaxy Action\n choose \nNew JBrowse Instance\n.\n\n\n\n\n\n\nClick \nInsert Track Group\n\n\n\n\n\n\nUnder \nTrack Category\n type in \ngene annotations\n.\n\n\n\n\n\n\nClick \nInsert Annotation Track\n\n\n\n\n\n\nFor \nTrack Type\n choose \nGFF/GFF3/BED/GBK Features\n\n\n\n\n\n\nUnder \nJBrowse Track Type[Advanced]\n select \nCanvas Features\n.\n\n\n\n\n\n\nUnder \nTrack Visibility\n choose \nOn for new users\n.\n\n\n\n\n\n\n\n\n\n\nNow we need to tell JBrowse the input files to use.\n\n\n\n\n\n\nJoin the Prokka output \nout_fna (fasta)\n to the JBrowse input \nSelect the reference genome\n\n\n\n\n\n\nJoin the Prokka output \nout_gff (gff)\n to the JBrowse input \nTrack Group 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick on the cog to save; again to run; choose input files; \nRun workflow\n; examine output files in current history.\n\n\n\n\n\n\nThe workflow will now assemble and annotate the genome, and create a JBrowse view of the annotations.\n\n\n\n\n\n\nJBrowse will produce one output file.\n\n\n\n\nClick on the eye icon to view.\n\n\nIn the centre drop down box, choose contig 1.\n\n\nUnder \nAvailable Tracks\n on the left, tick the boxes.\n\n\nZoom in and out with the plus and minus icons.\n\n\nThe blue blocks are the genome annotations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\n\nOur workflow is now:\n\n\n\n\nFASTQ\n sequence reads to Spades for assembly\n\n\nSpades \ncontigs fasta file\n to Prokka for annotation\n\n\nProkka \nfasta file\n and \n.gff file\n to JBrowse for visualisation.\n\n\n\n\n\n\n\n\nWe can re-run this workflow with different input FASTQ files.\n\n\n\n\n\n\nOther workflow options\n\n\nSaving outputs\n\n\nTo save only some output files:\n\n\n\n\nGo to the workflow canvas.\n\n\nFind the star next to the outputs.\n\n\nClick on the star for any outputs you want to save.\n\n\n\n\n\n\nTo save these starred files from the workflow output as a new history:\n\n\n\n\nBefore you click \nRun workflow\n, tick the box above to \nSend results to a new history\n.\n\n\n\n\nImport a workflow\n\n\nTo import an existing Galaxy Workflow:\n\n\n\n\nGo to the Workflow tab in the top panel.\n\n\nAt the top right, click on \nUpload or import workflow\n.\n\n\n\n\nExtract a workflow\n\n\nYou can extract a workflow from an existing Galaxy history.\n\n\n\n\nGo to your Galaxy history\n\n\nClick on the History cog icon and choose \nExtract Workflow\n.\n\n\nGive it a name and click \nCreate Workflow\n.\n\n\nTo edit, go to the Workflow tab, select the workflow, and choose \nEdit\n from the drop down menu. You can then edit the steps on the Workflow Canvas.\n\n\n\n\nA note on workflow tabs\n\n\nWe have been using the top Workflow tab. There is another tab at the bottom of the tool panel called Workflows. Click on \nWorkflows: All Workflows\n. This gives a similar view with a list of workflows.\n\n\nTo return to the main Galaxy window click on the \nAnalyze Data\n tab in the top panel.\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Galaxy workflows - introduction"
        }, 
        {
            "location": "/modules/workflows/#galaxy-workflows", 
            "text": "A workflow is a chain of analysis steps. In Galaxy, we can create a workflow from an existing analysis history, or we can create one visually by adding tools to a canvas.  This tutorial covers building a workflow to analyse a bacterial genome, from input FASTQ sequencing reads to assembly, annotation, and visualization.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Galaxy workflows"
        }, 
        {
            "location": "/modules/workflows/#start", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).  Import a history of data files:   Click on the  History  cog   Select  Import from File  In the box called  Archived History URL , paste in this link address to the Galaxy history of input files:   https://swift.rc.nectar.org.au:8888/v1/AUTH_377/public/Microbial_tutorials/Galaxy_history_input_files.tar.gz   Click  Import History  Wait a few seconds.  Click on the  View all histories  button   See if the Galaxy history has been imported: it will be called  imported from archive: Data  Above that pane, click on the  Switch to  button.  Then click  Analyze Data  (in the top menu bar).   You should now have a list of five files in your current history.    Re-name this history  Workflows .", 
            "title": "Start"
        }, 
        {
            "location": "/modules/workflows/#build-a-workflow", 
            "text": "We will first write a workflow for genome assembly.   In the top menu bar in Galaxy, click on  Workflow .     Click on the plus button.      Under  Workflow Name:  put in  Reads to Annotation .    Click  Save    This will bring up the  Workflow Canvas , a grid where you can arrange the workflow.", 
            "title": "Build a workflow"
        }, 
        {
            "location": "/modules/workflows/#add-inputs", 
            "text": "In the Tools panel, click  Inputs: Input datset  twice (at the very top of the list).    A box will appear: drag it to the left and there will be another box underneath it. Drag this also to the left. Your workflow canvas should look like this:       Click on the first box. Look in the right hand panel (now called  Details ). Under  Label  type in  R1.fastq . Press Enter for the change to be saved.    Repeat for the second input dataset box, naming that one  R2.fastq .", 
            "title": "Add inputs"
        }, 
        {
            "location": "/modules/workflows/#add-the-tool-spades", 
            "text": "In the tools panel, search for  spades  and click on the tool name.\nThis puts the spades box onto the workflow canvas.      Click on the spades box and look in the Details pane on the right. This shows all the options in spades. Choose:    Run only Assembly :  Yes  [the  Yes  button should be darker grey]   Kmers to use separated by commas:   33,55,91   [note: no spaces]    Coverage cutoff:   auto", 
            "title": "Add the tool \"spades\""
        }, 
        {
            "location": "/modules/workflows/#join-inputs-to-the-tool", 
            "text": "Now tell spades which input files to use.    Look at the input dataset box called  R1.fastq  and find the small arrow:     Click on this and drag the arrow over to the spades box input arrow   next to  Libraries 1   Files 1   Forward reads .      Repeat for the dataset box  R2.fastq , joining to the spades box next to  Libraries 1   Files 1   Reverse reads .", 
            "title": "Join inputs to the tool"
        }, 
        {
            "location": "/modules/workflows/#save-it-and-run", 
            "text": "Click on the cog at the top right of the workflow canvas and  Save .  Click the cog again and choose  Run .   This brings up a window where you specify the input datasets to use in the workflow.   Under  Step1: Input dataset  choose  mutant_R1.fastq .  Under  Step2: Input dataset  choose  mutant_R2.fastq .     Click  Run workflow .    This will run the workflow (spades) and save the output to the top of your current history in the right hand panel.   View some of the output files with the eye icon to check that the workflow (in this case, just spades) ran correctly.", 
            "title": "Save it and run"
        }, 
        {
            "location": "/modules/workflows/#add-to-the-worfklow", 
            "text": "We will add another tool to the workflow.    Go to the top Galaxy panel and click  Workflow .    Your workflow  Reads to Annotation  should be in the list. Click on the drop-down arrow next to this workflow and choose  Edit .    This will bring up the Workflow Canvas where we can add more inputs and tools.    In the Tools panel search for  Prokka  and click on the tool name. This will add a Prokka box to the workflow canvas.    We need to tell Prokka which genome assembly) to annotate. Join the spades output called  out_contigs(fasta)  to the Prokka input called  Contigs to annotate .    Click on the Prokka box and change some of the settings in the right hand Details panel:   Set the following parameters (leave everything else unchanged):  Locus tag prefix ( locustag) : P  Force GenBank/ENA/DDJB compliance ( compliant) :  No  Sequencing Centre ID ( centre) : V  Use genus-specific BLAST database   No        Click on the cog to the top right of the workflow canvas to save.    Click on the cog again to run.   Again, choose the input files:  mutant_R1.fastq  and  mutant_R2.fastq , and then click  Run workflow .     The output from the workflow (files from spades and prokka) will appear at the top of the History panel.    Click on the eye icon for some files to verify the workflow ran correctly.", 
            "title": "Add to the worfklow"
        }, 
        {
            "location": "/modules/workflows/#add-more-to-the-workflow", 
            "text": "We will add a visualization tool to view the genome annotation.    Go to the top Galaxy panel and click  Workflow .    Your workflow  Reads to Annotation  should be in the list. Click on the drop-down arrow next to this workflow and choose  Edit .    This will bring up the Workflow Canvas where we can add more inputs and tools.    In the Tools panel, search for  JBrowse  and click on  JBrowse genome browser . This will add a JBrowse box to the workflow canvas.    Click on the JBrowse box. In the Details pane:   Under  Reference genome to display  choose  Use a genome from history .   For  Produce a Standalone Instance  select  Yes .    For  Genetic Code  choose  11: The Bacterial, Archaeal and Plant Plastid Code .    Under  JBrowse-in-Galaxy Action  choose  New JBrowse Instance .    Click  Insert Track Group    Under  Track Category  type in  gene annotations .    Click  Insert Annotation Track    For  Track Type  choose  GFF/GFF3/BED/GBK Features    Under  JBrowse Track Type[Advanced]  select  Canvas Features .    Under  Track Visibility  choose  On for new users .      Now we need to tell JBrowse the input files to use.    Join the Prokka output  out_fna (fasta)  to the JBrowse input  Select the reference genome    Join the Prokka output  out_gff (gff)  to the JBrowse input  Track Group 1         Click on the cog to save; again to run; choose input files;  Run workflow ; examine output files in current history.    The workflow will now assemble and annotate the genome, and create a JBrowse view of the annotations.    JBrowse will produce one output file.   Click on the eye icon to view.  In the centre drop down box, choose contig 1.  Under  Available Tracks  on the left, tick the boxes.  Zoom in and out with the plus and minus icons.  The blue blocks are the genome annotations.", 
            "title": "Add more to the workflow"
        }, 
        {
            "location": "/modules/workflows/#summary", 
            "text": "Our workflow is now:   FASTQ  sequence reads to Spades for assembly  Spades  contigs fasta file  to Prokka for annotation  Prokka  fasta file  and  .gff file  to JBrowse for visualisation.     We can re-run this workflow with different input FASTQ files.", 
            "title": "Summary"
        }, 
        {
            "location": "/modules/workflows/#other-workflow-options", 
            "text": "", 
            "title": "Other workflow options"
        }, 
        {
            "location": "/modules/workflows/#saving-outputs", 
            "text": "To save only some output files:   Go to the workflow canvas.  Find the star next to the outputs.  Click on the star for any outputs you want to save.    To save these starred files from the workflow output as a new history:   Before you click  Run workflow , tick the box above to  Send results to a new history .", 
            "title": "Saving outputs"
        }, 
        {
            "location": "/modules/workflows/#import-a-workflow", 
            "text": "To import an existing Galaxy Workflow:   Go to the Workflow tab in the top panel.  At the top right, click on  Upload or import workflow .", 
            "title": "Import a workflow"
        }, 
        {
            "location": "/modules/workflows/#extract-a-workflow", 
            "text": "You can extract a workflow from an existing Galaxy history.   Go to your Galaxy history  Click on the History cog icon and choose  Extract Workflow .  Give it a name and click  Create Workflow .  To edit, go to the Workflow tab, select the workflow, and choose  Edit  from the drop down menu. You can then edit the steps on the Workflow Canvas.", 
            "title": "Extract a workflow"
        }, 
        {
            "location": "/modules/workflows/#a-note-on-workflow-tabs", 
            "text": "We have been using the top Workflow tab. There is another tab at the bottom of the tool panel called Workflows. Click on  Workflows: All Workflows . This gives a similar view with a list of workflows.  To return to the main Galaxy window click on the  Analyze Data  tab in the top panel.", 
            "title": "A note on workflow tabs"
        }, 
        {
            "location": "/modules/workflows/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/workflow-assembly/", 
            "text": "Workflow: Genome Assembly\n\n\nCreate a Galaxy workflow\n\n\nGalaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nGenome assembly\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\n\n\nBefore we create a workflow for genome assembly, we need the correct files in our current Galaxy history. We can get these files in two ways:\n\n\n\n\n\n\nEither follow the tutorial on \ngenome assembly\n\n\n\n\n\n\nOr, obtain the files from a Shared History (Galaxy Australia only).\n\n\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-assembly-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\n\n\n\n\nWhen you have completed this tutorial or imported the history, you will have the correct files in your history panel.\n\n\nExtract the Workflow\n\n\n\n\nIn the history panel, click on the cog icon.\n\n\nClick \nExtract Workflow\n\n\nIf all looks ok, click \nCreate Workflow\n\n\nIn the centre panel, click \nedit\n\n\n\n\n\n\nThis brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.\n\n\n\n\n\n\nDrag the panes around until your workflow is clear.\n\n\nIn the top right corner click on the cog icon and \nSave\n\n\n\n\nClick on the cog icon again and \nRun\n\n\n\n\nSend results to a new history\n: \nYes\n\n\nCheck all input files are correct and change if necessary\n\n\nIn the top right corner \nRun workflow\n\n\n\n\n\n\n\n\nThis workflow will now run.\n\n\n\n\nIn the History panel, click on the \nView all histories\n icon\n\n\n\nFind your workflow history and \nSwitch to\n it.\n\n\n\n\nTo see all your workflows, go to the top panel in Galaxy and click \nWorkflow\n.\n\n\n\n\nYou can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Workflow - genome assembly"
        }, 
        {
            "location": "/modules/workflow-assembly/#workflow-genome-assembly", 
            "text": "", 
            "title": "Workflow: Genome Assembly"
        }, 
        {
            "location": "/modules/workflow-assembly/#create-a-galaxy-workflow", 
            "text": "Galaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Create a Galaxy workflow"
        }, 
        {
            "location": "/modules/workflow-assembly/#genome-assembly", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).   Before we create a workflow for genome assembly, we need the correct files in our current Galaxy history. We can get these files in two ways:    Either follow the tutorial on  genome assembly    Or, obtain the files from a Shared History (Galaxy Australia only).   Go to  Shared Data  Click  Histories  Click  Completed-assembly-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.     When you have completed this tutorial or imported the history, you will have the correct files in your history panel.", 
            "title": "Genome assembly"
        }, 
        {
            "location": "/modules/workflow-assembly/#extract-the-workflow", 
            "text": "In the history panel, click on the cog icon.  Click  Extract Workflow  If all looks ok, click  Create Workflow  In the centre panel, click  edit    This brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.    Drag the panes around until your workflow is clear.  In the top right corner click on the cog icon and  Save   Click on the cog icon again and  Run   Send results to a new history :  Yes  Check all input files are correct and change if necessary  In the top right corner  Run workflow     This workflow will now run.   In the History panel, click on the  View all histories  icon  Find your workflow history and  Switch to  it.   To see all your workflows, go to the top panel in Galaxy and click  Workflow .   You can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.", 
            "title": "Extract the Workflow"
        }, 
        {
            "location": "/modules/workflow-assembly/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/workflow-annotation/", 
            "text": "Workflow: Genome Annotation\n\n\nCreate a Galaxy workflow\n\n\nGalaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nGenome annotation\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\n\n\nBefore we create a workflow for genome annotation, we need the correct files in our current Galaxy history. We can get these files in two ways:\n\n\n\n\n\n\nEither follow the tutorial on \ngenome annotation\n\n\n\n\n\n\nOr, obtain the files from a Shared History (Galaxy Australia only).\n\n\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-annotation-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\n\n\n\n\nWhen you have completed this tutorial or imported the history, you will have the correct files in your history panel.\n\n\nExtract the Workflow\n\n\n\n\nIn the history panel, click on the cog icon.\n\n\nClick \nExtract Workflow\n\n\nIf all looks ok, click \nCreate Workflow\n\n\nIn the centre panel, click \nedit\n\n\n\n\nThis brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.\n\n\n\n\n\n\nDrag the panes around until your workflow is clear.\n\n\nIn the top right corner click on the cog icon and \nSave\n\n\n\n\nClick on the cog icon again and \nRun\n\n\n\n\nSend results to a new history\n: \nYes\n\n\nCheck all input files are correct and change if necessary\n\n\nIn the top right corner \nRun workflow\n\n\n\n\n\n\n\n\nThis workflow will now run.\n\n\n\n\nIn the History panel, click on the \nView all histories\n icon\n\n\n\nFind your workflow history and \nSwitch to\n it.\n\n\n\n\nTo see all your workflows, go to the top panel in Galaxy and click \nWorkflow\n.\n\n\n\n\nYou can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Workflow - genome annotation"
        }, 
        {
            "location": "/modules/workflow-annotation/#workflow-genome-annotation", 
            "text": "", 
            "title": "Workflow: Genome Annotation"
        }, 
        {
            "location": "/modules/workflow-annotation/#create-a-galaxy-workflow", 
            "text": "Galaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Create a Galaxy workflow"
        }, 
        {
            "location": "/modules/workflow-annotation/#genome-annotation", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).   Before we create a workflow for genome annotation, we need the correct files in our current Galaxy history. We can get these files in two ways:    Either follow the tutorial on  genome annotation    Or, obtain the files from a Shared History (Galaxy Australia only).   Go to  Shared Data  Click  Histories  Click  Completed-annotation-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.     When you have completed this tutorial or imported the history, you will have the correct files in your history panel.", 
            "title": "Genome annotation"
        }, 
        {
            "location": "/modules/workflow-annotation/#extract-the-workflow", 
            "text": "In the history panel, click on the cog icon.  Click  Extract Workflow  If all looks ok, click  Create Workflow  In the centre panel, click  edit   This brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.    Drag the panes around until your workflow is clear.  In the top right corner click on the cog icon and  Save   Click on the cog icon again and  Run   Send results to a new history :  Yes  Check all input files are correct and change if necessary  In the top right corner  Run workflow     This workflow will now run.   In the History panel, click on the  View all histories  icon  Find your workflow history and  Switch to  it.   To see all your workflows, go to the top panel in Galaxy and click  Workflow .   You can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.", 
            "title": "Extract the Workflow"
        }, 
        {
            "location": "/modules/workflow-annotation/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/workflow-variant-calling/", 
            "text": "Workflow: Variant Calling\n\n\nCreate a Galaxy workflow\n\n\nGalaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nVariant calling\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\n\n\nBefore we create a workflow for variant calling, we need the correct files in our current Galaxy history. We can get these files in two ways:\n\n\n\n\n\n\nEither follow the tutorial on \nvariant calling\n\n\n\n\n\n\nOr, obtain the files from a Shared History (Galaxy Australia only).\n\n\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-variant-calling-analysis\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\n\n\n\n\nWhen you have completed this tutorial or imported the history, you will have the correct files in your history panel.\n\n\nExtract the Workflow\n\n\n\n\nIn the history panel, click on the cog icon.\n\n\nClick \nExtract Workflow\n\n\nIf all looks ok, click \nCreate Workflow\n\n\nIn the centre panel, click \nedit\n\n\n\n\nThis brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.\n\n\n\n\n\n\nDrag the panes around until your workflow is clear.\n\n\nIn the top right corner click on the cog icon and \nSave\n\n\n\n\nClick on the cog icon again and \nRun\n\n\n\n\nSend results to a new history\n: \nYes\n\n\nCheck all input files are correct and change if necessary\n\n\nIn the top right corner \nRun workflow\n\n\n\n\n\n\n\n\nThis workflow will now run.\n\n\n\n\nIn the History panel, click on the \nView all histories\n icon\n\n\n\nFind your workflow history and \nSwitch to\n it.\n\n\n\n\nTo see all your workflows, go to the top panel in Galaxy and click \nWorkflow\n.\n\n\n\n\nYou can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Workflow - variant calling, bacteria"
        }, 
        {
            "location": "/modules/workflow-variant-calling/#workflow-variant-calling", 
            "text": "", 
            "title": "Workflow: Variant Calling"
        }, 
        {
            "location": "/modules/workflow-variant-calling/#create-a-galaxy-workflow", 
            "text": "Galaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Create a Galaxy workflow"
        }, 
        {
            "location": "/modules/workflow-variant-calling/#variant-calling", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).   Before we create a workflow for variant calling, we need the correct files in our current Galaxy history. We can get these files in two ways:    Either follow the tutorial on  variant calling    Or, obtain the files from a Shared History (Galaxy Australia only).   Go to  Shared Data  Click  Histories  Click  Completed-variant-calling-analysis  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.     When you have completed this tutorial or imported the history, you will have the correct files in your history panel.", 
            "title": "Variant calling"
        }, 
        {
            "location": "/modules/workflow-variant-calling/#extract-the-workflow", 
            "text": "In the history panel, click on the cog icon.  Click  Extract Workflow  If all looks ok, click  Create Workflow  In the centre panel, click  edit   This brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.    Drag the panes around until your workflow is clear.  In the top right corner click on the cog icon and  Save   Click on the cog icon again and  Run   Send results to a new history :  Yes  Check all input files are correct and change if necessary  In the top right corner  Run workflow     This workflow will now run.   In the History panel, click on the  View all histories  icon  Find your workflow history and  Switch to  it.   To see all your workflows, go to the top panel in Galaxy and click  Workflow .   You can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.", 
            "title": "Extract the Workflow"
        }, 
        {
            "location": "/modules/workflow-variant-calling/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }, 
        {
            "location": "/modules/workflow-rna-seq/", 
            "text": "Workflow: RNA-Seq\n\n\nCreate a Galaxy workflow\n\n\nGalaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.\n\n\nNew to Galaxy?\n First try the \nintroduction\n and then learn some \nkey tasks\n\n\nRNA-Seq\n\n\n\n\nLog in to your Galaxy instance (for example, Galaxy Australia, \nusegalaxy.org.au\n).\n\n\n\n\nBefore we create a workflow for RNA-seq, we need the correct files in our current Galaxy history. We can get these files in two ways:\n\n\n\n\n\n\nEither follow the tutorial on \nRNA-seq\n\n\n\n\n\n\nOr, obtain the files from a Shared History (Galaxy Australia only).\n\n\n\n\nGo to \nShared Data\n\n\nClick \nHistories\n\n\nClick \nCompleted-RNA-seq-bacteria\n\n\nClick \nImport\n (at the top right corner)\n\n\nThe analysis should now be showing as your current history.\n\n\n\n\n\n\n\n\nWhen you have completed this tutorial or imported the history, you will have the correct files in your history panel.\n\n\nExtract the Workflow\n\n\n\n\nIn the history panel, click on the cog icon.\n\n\nClick \nExtract Workflow\n\n\nIf all looks ok, click \nCreate Workflow\n\n\nIn the centre panel, click \nedit\n\n\n\n\nThis brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.\n\n\n\n\n\n\nDrag the panes around until your workflow is clear.\n\n\nIn the top right corner click on the cog icon and \nSave\n\n\n\n\nClick on the cog icon again and \nRun\n\n\n\n\nSend results to a new history\n: \nYes\n\n\nCheck all input files are correct and change if necessary\n\n\nIn the top right corner \nRun workflow\n\n\n\n\n\n\n\n\nThis workflow will now run.\n\n\n\n\nIn the History panel, click on the \nView all histories\n icon\n\n\n\nFind your workflow history and \nSwitch to\n it.\n\n\n\n\nTo see all your workflows, go to the top panel in Galaxy and click \nWorkflow\n.\n\n\n\n\nYou can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.\n\n\n\n\nWhat\ns next?\n\n\nTo use the tutorials on this website:\n\n\n\n\n see the list in the left hand panel\n\n\n or, click the \nmenu button\n (three horizontal bars) in the top left of the page\n\n\n\n\nYou can find more tutorials at the Galaxy Training Network:\n\n\n\n\nhttp://galaxyproject.github.io/training-material/", 
            "title": "Workflow - RNA-seq"
        }, 
        {
            "location": "/modules/workflow-rna-seq/#workflow-rna-seq", 
            "text": "", 
            "title": "Workflow: RNA-Seq"
        }, 
        {
            "location": "/modules/workflow-rna-seq/#create-a-galaxy-workflow", 
            "text": "Galaxy provides the option to extract a workflow based on the steps you just followed and the tools and parameters used.  New to Galaxy?  First try the  introduction  and then learn some  key tasks", 
            "title": "Create a Galaxy workflow"
        }, 
        {
            "location": "/modules/workflow-rna-seq/#rna-seq", 
            "text": "Log in to your Galaxy instance (for example, Galaxy Australia,  usegalaxy.org.au ).   Before we create a workflow for RNA-seq, we need the correct files in our current Galaxy history. We can get these files in two ways:    Either follow the tutorial on  RNA-seq    Or, obtain the files from a Shared History (Galaxy Australia only).   Go to  Shared Data  Click  Histories  Click  Completed-RNA-seq-bacteria  Click  Import  (at the top right corner)  The analysis should now be showing as your current history.     When you have completed this tutorial or imported the history, you will have the correct files in your history panel.", 
            "title": "RNA-Seq"
        }, 
        {
            "location": "/modules/workflow-rna-seq/#extract-the-workflow", 
            "text": "In the history panel, click on the cog icon.  Click  Extract Workflow  If all looks ok, click  Create Workflow  In the centre panel, click  edit   This brings up the workflow canvas, a space for graphically viewing and re-arranging your workflow.    Drag the panes around until your workflow is clear.  In the top right corner click on the cog icon and  Save   Click on the cog icon again and  Run   Send results to a new history :  Yes  Check all input files are correct and change if necessary  In the top right corner  Run workflow     This workflow will now run.   In the History panel, click on the  View all histories  icon  Find your workflow history and  Switch to  it.   To see all your workflows, go to the top panel in Galaxy and click  Workflow .   You can edit or run workflows from here by clicking on the drop-down arrow next to each workflow.", 
            "title": "Extract the Workflow"
        }, 
        {
            "location": "/modules/workflow-rna-seq/#whats-next", 
            "text": "To use the tutorials on this website:    see the list in the left hand panel   or, click the  menu button  (three horizontal bars) in the top left of the page   You can find more tutorials at the Galaxy Training Network:   http://galaxyproject.github.io/training-material/", 
            "title": "What's next?"
        }
    ]
}